<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ø¢Ù…ÙˆØ²Ø´ Ú©Ø§Ù…Ù„ Embeddings - Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø¬Ø§Ø³Ø§Ø²ÛŒ</title>
    <link href="https://fonts.googleapis.com/css2?family=Vazirmatn:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Vazirmatn', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            line-height: 1.8;
            color: #333;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        .slide {
            background: white;
            border-radius: 20px;
            padding: 60px;
            margin-bottom: 30px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.1);
            position: relative;
            overflow: hidden;
        }
        
        .slide::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 5px;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        }
        
        .slide-number {
            position: absolute;
            top: 20px;
            left: 20px;
            width: 50px;
            height: 50px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 700;
            font-size: 1.2em;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }
        
        h1 {
            color: #667eea;
            font-size: 3em;
            margin-bottom: 20px;
            font-weight: 800;
        }
        
        h2 {
            color: #667eea;
            font-size: 2.5em;
            margin-bottom: 30px;
            font-weight: 700;
            padding-bottom: 15px;
            border-bottom: 3px solid #667eea;
        }
        
        h3 {
            color: #764ba2;
            font-size: 1.8em;
            margin: 30px 0 20px 0;
            font-weight: 600;
        }
        
        h4 {
            color: #667eea;
            font-size: 1.4em;
            margin: 20px 0 15px 0;
            font-weight: 600;
        }
        
        p, li {
            font-size: 1.2em;
            margin-bottom: 15px;
            color: #555;
        }
        
        .emoji {
            font-size: 1.3em;
            margin-left: 10px;
        }
        
        .box {
            padding: 25px;
            border-radius: 15px;
            margin: 25px 0;
            border-right: 5px solid;
        }
        
        .definition {
            background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
            border-color: #2196f3;
        }
        
        .example {
            background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);
            border-color: #9c27b0;
        }
        
        .info {
            background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%);
            border-color: #4caf50;
        }
        
        .warning {
            background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
            border-color: #ff9800;
        }
        
        .danger {
            background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
            border-color: #f44336;
        }
        
        .success {
            background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%);
            border-color: #4caf50;
        }
        
        .key-point {
            background: linear-gradient(135deg, #fff9c4 0%, #fff59d 100%);
            border-color: #fbc02d;
            font-weight: 500;
        }
        
        .highlight {
            background: linear-gradient(135deg, #e1f5fe 0%, #b3e5fc 100%);
            border-color: #03a9f4;
        }
        
        .code {
            background: #1e293b;
            color: #e2e8f0;
            padding: 25px;
            border-radius: 12px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 1em;
            line-height: 1.6;
            margin: 20px 0;
            position: relative;
            direction: ltr;
            text-align: left;
            white-space: pre-wrap;
        }
        
        .code::before {
            content: 'Python';
            position: absolute;
            top: 10px;
            right: 10px;
            background: #667eea;
            color: white;
            padding: 5px 15px;
            border-radius: 5px;
            font-size: 0.8em;
            font-weight: 600;
        }
        
        .code .keyword {
            color: #c792ea;
            font-weight: 600;
        }
        
        .code .string {
            color: #c3e88d;
        }
        
        .code .comment {
            color: #676e95;
            font-style: italic;
        }
        
        .code .function {
            color: #82aaff;
        }
        
        .code .number {
            color: #f78c6c;
        }
        
        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            margin: 30px 0;
        }
        
        .card {
            background: white;
            padding: 25px;
            border-radius: 15px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            border-top: 4px solid #667eea;
        }
        
        .card:hover {
            transform: translateY(-10px);
            box-shadow: 0 8px 25px rgba(0,0,0,0.15);
        }
        
        .card h4 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.3em;
        }
        
        .card ul {
            list-style: none;
            padding: 0;
        }
        
        .card li {
            padding: 8px 0;
            border-bottom: 1px solid #eee;
        }
        
        .card li:last-child {
            border-bottom: none;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }
        
        thead {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
        
        th, td {
            padding: 15px;
            text-align: right;
            border-bottom: 1px solid #eee;
        }
        
        th {
            font-weight: 600;
            font-size: 1.1em;
        }
        
        tbody tr:hover {
            background: #f5f5f5;
        }
        
        tbody tr:nth-child(even) {
            background: #fafafa;
        }
        
        ul, ol {
            padding-right: 30px;
            margin: 20px 0;
        }
        
        li {
            margin: 10px 0;
            line-height: 1.8;
        }
        
        strong {
            color: #667eea;
            font-weight: 600;
        }
        
        .architecture-diagram {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 40px;
            border-radius: 15px;
            margin: 30px 0;
            text-align: center;
        }
        
        .component-box {
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin: 15px auto;
            max-width: 400px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            font-weight: 600;
            color: #667eea;
            border: 2px solid #667eea;
        }
        
        .arrow {
            font-size: 2em;
            color: #667eea;
            margin: 10px 0;
        }
        
        .comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: 30px 0;
        }
        
        @media (max-width: 768px) {
            .slide {
                padding: 30px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            h2 {
                font-size: 1.8em;
            }
            
            .grid {
                grid-template-columns: 1fr;
            }
            
            .comparison {
                grid-template-columns: 1fr;
            }
        }
        
        .vector-visualization {
            background: #f8f9fa;
            padding: 30px;
            border-radius: 15px;
            margin: 25px 0;
            border: 2px dashed #667eea;
        }
        
        .vector-item {
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 10px 15px;
            margin: 5px;
            border-radius: 8px;
            font-weight: 600;
            box-shadow: 0 2px 10px rgba(102, 126, 234, 0.3);
        }
        
        .similarity-demo {
            background: linear-gradient(135deg, #e8eaf6 0%, #c5cae9 100%);
            padding: 30px;
            border-radius: 15px;
            margin: 25px 0;
        }
        
        .text-pair {
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .similarity-score {
            display: inline-block;
            background: #4caf50;
            color: white;
            padding: 8px 20px;
            border-radius: 20px;
            font-weight: 700;
            margin-top: 10px;
        }
        
        .math-formula {
            background: #f5f5f5;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            text-align: center;
            font-family: 'Courier New', monospace;
            font-size: 1.3em;
            color: #667eea;
            border: 2px solid #667eea;
        }
        
        .dimension-chart {
            display: flex;
            align-items: flex-end;
            justify-content: space-around;
            height: 200px;
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin: 25px 0;
        }
        
        .dimension-bar {
            background: linear-gradient(to top, #667eea 0%, #764ba2 100%);
            width: 60px;
            border-radius: 5px 5px 0 0;
            position: relative;
            transition: all 0.3s ease;
        }
        
        .dimension-bar:hover {
            transform: scale(1.1);
        }
        
        .dimension-label {
            position: absolute;
            bottom: -30px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 0.8em;
            white-space: nowrap;
        }
    </style>
</head>
<body>
    <div class="container">
        
        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 1: ØµÙØ­Ù‡ Ø¹Ù†ÙˆØ§Ù† -->
        <div class="slide">
            <div class="slide-number">1</div>
            <h1 style="text-align: center; color: #667eea; margin-top: 60px;">
                <span class="emoji">ğŸ§®</span>
                Ø¢Ù…ÙˆØ²Ø´ Ø¬Ø§Ù…Ø¹ Embeddings
            </h1>
            <h2 style="text-align: center; color: #764ba2; font-size: 2em; border: none;">
                Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø¬Ø§Ø³Ø§Ø²ÛŒ Ø¯Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†
            </h2>
            
            <div class="highlight box" style="margin-top: 50px;">
                <h3 style="text-align: center;"><span class="emoji">ğŸ¯</span> Embedding Ú†ÛŒØ³ØªØŸ</h3>
                <p style="text-align: center; font-size: 1.4em; line-height: 2;">
                    ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ (Ù…ØªÙ†ØŒ ØªØµÙˆÛŒØ±ØŒ ØµØ¯Ø§) Ø¨Ù‡ <strong>Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ</strong> 
                    Ú©Ù‡ Ù…Ø§Ø´ÛŒÙ† Ø¨ØªÙˆØ§Ù†Ø¯ Ø¨Ø§ Ø¢Ù†â€ŒÙ‡Ø§ Ú©Ø§Ø± Ú©Ù†Ø¯ Ùˆ <strong>Ù…Ø¹Ù†Ø§ÛŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø±Ú© Ú©Ù†Ø¯</strong>.
                </p>
            </div>
            
            <div class="grid" style="margin-top: 50px;">
                <div class="card">
                    <h4><span class="emoji">ğŸ“</span> Ù…ØªÙ† Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø±</h4>
                    <p>"Ø³Ù„Ø§Ù…" â†’ [0.23, -0.45, 0.67, ...]</p>
                </div>
                
                <div class="card">
                    <h4><span class="emoji">ğŸ–¼ï¸</span> ØªØµÙˆÛŒØ± Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø±</h4>
                    <p>Ø¹Ú©Ø³ Ú¯Ø±Ø¨Ù‡ â†’ [0.12, 0.89, -0.34, ...]</p>
                </div>
                
                <div class="card">
                    <h4><span class="emoji">ğŸµ</span> ØµØ¯Ø§ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø±</h4>
                    <p>ØµØ¯Ø§ÛŒ Ù…ÙˆØ³ÛŒÙ‚ÛŒ â†’ [0.56, -0.23, 0.91, ...]</p>
                </div>
            </div>
            
            <div class="key-point box" style="margin-top: 50px;">
                <h3><span class="emoji">ğŸ’¡</span> Ú†Ø±Ø§ Embedding Ù…Ù‡Ù… Ø§Ø³ØªØŸ</h3>
                <ul style="font-size: 1.2em;">
                    <li>âœ… Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± ÙÙ‚Ø· Ø¨Ø§ Ø§Ø¹Ø¯Ø§Ø¯ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯</li>
                    <li>âœ… Ù…Ø¹Ù†Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ú©Ù„Ù…Ø§Øª Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ø¯</li>
                    <li>âœ… Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ØŒ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù†Ø²Ø¯ÛŒÚ© Ø¯Ø§Ø±Ù†Ø¯</li>
                    <li>âœ… Ù¾Ø§ÛŒÙ‡ ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ø±Ù† AI Ø§Ø³Øª</li>
                </ul>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 2: Ù…ÙÙ‡ÙˆÙ… Ù¾Ø§ÛŒÙ‡ -->
        <div class="slide">
            <div class="slide-number">2</div>
            <h2>ğŸ§  Ù…ÙÙ‡ÙˆÙ… Ù¾Ø§ÛŒÙ‡ Embedding</h2>
            
            <div class="definition box">
                <h3><span class="emoji">ğŸ“–</span> ØªØ¹Ø±ÛŒÙ Ø³Ø§Ø¯Ù‡</h3>
                <p style="font-size: 1.3em;">
                    <strong>Embedding</strong> ÛŒØ¹Ù†ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª (Ù…Ø«Ù„ Ú©Ù„Ù…Ø§Øª) Ø¨Ù‡ 
                    <strong>Ø¢Ø±Ø§ÛŒÙ‡â€ŒØ§ÛŒ Ø§Ø² Ø§Ø¹Ø¯Ø§Ø¯</strong> Ú©Ù‡ Ù…Ø¹Ù†Ø§ÛŒ Ø¢Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ø§ Ø¯Ø± ÙØ¶Ø§ÛŒ Ú†Ù†Ø¯Ø¨Ø¹Ø¯ÛŒ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ø¯.
                </p>
            </div>
            
            <h3><span class="emoji">ğŸ”¢</span> Ù…Ø«Ø§Ù„ Ø³Ø§Ø¯Ù‡: Ú©Ù„Ù…Ù‡ "Ù¾Ø§Ø¯Ø´Ø§Ù‡"</h3>
            
            <div class="vector-visualization">
                <h4 style="text-align: center; margin-bottom: 20px;">Ø¨Ø±Ø¯Ø§Ø± 8 Ø¨Ø¹Ø¯ÛŒ</h4>
                <div style="text-align: center;">
                    <span class="vector-item">0.234</span>
                    <span class="vector-item">-0.567</span>
                    <span class="vector-item">0.891</span>
                    <span class="vector-item">0.123</span>
                    <span class="vector-item">-0.345</span>
                    <span class="vector-item">0.678</span>
                    <span class="vector-item">0.456</span>
                    <span class="vector-item">-0.789</span>
                </div>
                <p style="text-align: center; margin-top: 20px; color: #667eea; font-weight: 600;">
                    Ù‡Ø± Ø¹Ø¯Ø¯ ÛŒÚ© ÙˆÛŒÚ˜Ú¯ÛŒ Ø§Ø² Ù…Ø¹Ù†Ø§ÛŒ Ú©Ù„Ù…Ù‡ Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
                </p>
            </div>
            
            <h3><span class="emoji">ğŸ¯</span> ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Embedding Ø®ÙˆØ¨</h3>
            
            <div class="grid">
                <div class="card">
                    <h4>1ï¸âƒ£ Ø­ÙØ¸ Ù…Ø¹Ù†Ø§</h4>
                    <p>Ú©Ù„Ù…Ø§Øª Ø¨Ø§ Ù…Ø¹Ù†Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ØŒ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ù‡Ù… Ø¯Ø§Ø±Ù†Ø¯</p>
                    <p><strong>Ù…Ø«Ø§Ù„:</strong> "Ù¾Ø§Ø¯Ø´Ø§Ù‡" Ùˆ "Ù…Ù„Ú©Ù‡" Ù†Ø²Ø¯ÛŒÚ©â€ŒØ§Ù†Ø¯</p>
                </div>
                
                <div class="card">
                    <h4>2ï¸âƒ£ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ù†Ø§ÛŒÛŒ</h4>
                    <p>Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ† Ú©Ù„Ù…Ø§Øª Ø­ÙØ¸ Ù…ÛŒâ€ŒØ´ÙˆØ¯</p>
                    <p><strong>Ù…Ø«Ø§Ù„:</strong> Ù¾Ø§Ø¯Ø´Ø§Ù‡ - Ù…Ø±Ø¯ + Ø²Ù† = Ù…Ù„Ú©Ù‡</p>
                </div>
                
                <div class="card">
                    <h4>3ï¸âƒ£ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ</h4>
                    <p>Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ§Ø¯ Ø¯Ø± ÙØ¶Ø§ÛŒ Ú©ÙˆÚ†Ú©</p>
                    <p><strong>Ù…Ø«Ø§Ù„:</strong> Ù…ÛŒÙ„ÛŒÙˆÙ†â€ŒÙ‡Ø§ Ú©Ù„Ù…Ù‡ â†’ 300 Ø¨Ø¹Ø¯</p>
                </div>
                
                <div class="card">
                    <h4>4ï¸âƒ£ Ù‚Ø§Ø¨Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡</h4>
                    <p>Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø´Ø¨Ø§Ù‡Øª Ø±Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú¯Ø±ÙØª</p>
                    <p><strong>Ù…Ø«Ø§Ù„:</strong> Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§</p>
                </div>
            </div>
            
            <div class="example box">
                <h3><span class="emoji">ğŸ’­</span> ØªÙØ§ÙˆØª Ø¨Ø§ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Ø±ÙˆØ´</th>
                            <th>One-Hot Encoding</th>
                            <th>Embedding</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø±Ø¯Ø§Ø±</strong></td>
                            <td>Ø¨Ø±Ø§Ø¨Ø± ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª (Ù…Ø«Ù„Ø§Ù‹ 50000)</td>
                            <td>Ø«Ø§Ø¨Øª (Ù…Ø«Ù„Ø§Ù‹ 300)</td>
                        </tr>
                        <tr>
                            <td><strong>Ø­ÙØ¸ Ù…Ø¹Ù†Ø§</strong></td>
                            <td>âŒ Ø®ÛŒØ±</td>
                            <td>âœ… Ø¨Ù„Ù‡</td>
                        </tr>
                        <tr>
                            <td><strong>Ø´Ø¨Ø§Ù‡Øª</strong></td>
                            <td>Ù‡Ù…Ù‡ Ú©Ù„Ù…Ø§Øª ÛŒÚ©Ø³Ø§Ù†</td>
                            <td>Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ Ù†Ø²Ø¯ÛŒÚ©</td>
                        </tr>
                        <tr>
                            <td><strong>Ø­Ø§ÙØ¸Ù‡</strong></td>
                            <td>Ø²ÛŒØ§Ø¯ (sparse)</td>
                            <td>Ú©Ù… (dense)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 3: Ø§Ù†ÙˆØ§Ø¹ Embeddings -->
        <div class="slide">
            <div class="slide-number">3</div>
            <h2>ğŸ“š Ø§Ù†ÙˆØ§Ø¹ Embeddings</h2>
            
            <h3><span class="emoji">1ï¸âƒ£</span> Word Embeddings - Ø¨Ø±Ø¯Ø§Ø± Ú©Ù„Ù…Ø§Øª</h3>
            
            <div class="info box">
                <h4>ØªØ¹Ø±ÛŒÙ</h4>
                <p>ØªØ¨Ø¯ÛŒÙ„ Ù‡Ø± Ú©Ù„Ù…Ù‡ Ø¨Ù‡ ÛŒÚ© Ø¨Ø±Ø¯Ø§Ø± Ø¹Ø¯Ø¯ÛŒ Ú©Ù‡ Ù…Ø¹Ù†Ø§ÛŒ Ø¢Ù† Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.</p>
            </div>
            
            <div class="grid">
                <div class="card">
                    <h4><span class="emoji">ğŸ›ï¸</span> Word2Vec</h4>
                    <p><strong>ØªÙˆØ³Ø¹Ù‡:</strong> Google (2013)</p>
                    <p><strong>Ø±ÙˆØ´:</strong> CBOW Ùˆ Skip-gram</p>
                    <p><strong>Ø§Ø¨Ø¹Ø§Ø¯:</strong> Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 100-300</p>
                    <p><strong>Ù…Ø²ÛŒØª:</strong> Ø³Ø±ÛŒØ¹ Ùˆ Ú©Ø§Ø±Ø¢Ù…Ø¯</p>
                </div>
                
                <div class="card">
                    <h4><span class="emoji">ğŸŒ</span> GloVe</h4>
                    <p><strong>ØªÙˆØ³Ø¹Ù‡:</strong> Stanford (2014)</p>
                    <p><strong>Ø±ÙˆØ´:</strong> Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…â€ŒØ±Ø®Ø¯Ø§Ø¯ÛŒ</p>
                    <p><strong>Ø§Ø¨Ø¹Ø§Ø¯:</strong> 50, 100, 200, 300</p>
                    <p><strong>Ù…Ø²ÛŒØª:</strong> Ø±ÙˆØ§Ø¨Ø· Ø¬Ù‡Ø§Ù†ÛŒ</p>
                </div>
                
                <div class="card">
                    <h4><span class="emoji">âš¡</span> FastText</h4>
                    <p><strong>ØªÙˆØ³Ø¹Ù‡:</strong> Facebook (2016)</p>
                    <p><strong>Ø±ÙˆØ´:</strong> Ø²ÛŒØ±Ú©Ù„Ù…Ø§Øª (subwords)</p>
                    <p><strong>Ø§Ø¨Ø¹Ø§Ø¯:</strong> 100-300</p>
                    <p><strong>Ù…Ø²ÛŒØª:</strong> Ú©Ù„Ù…Ø§Øª Ø¬Ø¯ÛŒØ¯</p>
                </div>
            </div>
            
            <h3><span class="emoji">2ï¸âƒ£</span> Contextual Embeddings - Ø¨Ø±Ø¯Ø§Ø± Ù…ØªÙ†ÛŒ</h3>
            
            <div class="warning box">
                <h4>ØªÙØ§ÙˆØª Ú©Ù„ÛŒØ¯ÛŒ</h4>
                <p>Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ´ØŒ <strong>Ø¨Ø±Ø¯Ø§Ø± Ù‡Ø± Ú©Ù„Ù…Ù‡ Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ø¬Ù…Ù„Ù‡ ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯</strong>!</p>
                <p><strong>Ù…Ø«Ø§Ù„:</strong> Ú©Ù„Ù…Ù‡ "Ø¨Ø§Ù†Ú©" Ø¯Ø± "Ø¨Ø§Ù†Ú© Ù…Ù„ÛŒ" Ùˆ "Ø¨Ø§Ù†Ú© Ø±ÙˆØ¯Ø®Ø§Ù†Ù‡" Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª Ø¯Ø§Ø±Ø¯.</p>
            </div>
            
            <div class="grid">
                <div class="card">
                    <h4><span class="emoji">ğŸ¤–</span> BERT</h4>
                    <p><strong>ØªÙˆØ³Ø¹Ù‡:</strong> Google (2018)</p>
                    <p><strong>Ø§Ø¨Ø¹Ø§Ø¯:</strong> 768 (base), 1024 (large)</p>
                    <p><strong>ÙˆÛŒÚ˜Ú¯ÛŒ:</strong> Ø¯ÙˆØ·Ø±ÙÙ‡</p>
                    <p><strong>Ú©Ø§Ø±Ø¨Ø±Ø¯:</strong> Ø¯Ø±Ú© Ù…ØªÙ†</p>
                </div>
                
                <div class="card">
                    <h4><span class="emoji">ğŸš€</span> GPT</h4>
                    <p><strong>ØªÙˆØ³Ø¹Ù‡:</strong> OpenAI</p>
                    <p><strong>Ø§Ø¨Ø¹Ø§Ø¯:</strong> 768-12288</p>
                    <p><strong>ÙˆÛŒÚ˜Ú¯ÛŒ:</strong> ÛŒÚ©â€ŒØ·Ø±ÙÙ‡</p>
                    <p><strong>Ú©Ø§Ø±Ø¨Ø±Ø¯:</strong> ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†</p>
                </div>
                
                <div class="card">
                    <h4><span class="emoji">ğŸŒŸ</span> Sentence-BERT</h4>
                    <p><strong>ØªÙˆØ³Ø¹Ù‡:</strong> UKP Lab (2019)</p>
                    <p><strong>Ø§Ø¨Ø¹Ø§Ø¯:</strong> 384-768</p>
                    <p><strong>ÙˆÛŒÚ˜Ú¯ÛŒ:</strong> Ø¬Ù…Ù„Ù‡ Ú©Ø§Ù…Ù„</p>
                    <p><strong>Ú©Ø§Ø±Ø¨Ø±Ø¯:</strong> Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¬Ù…Ù„Ø§Øª</p>
                </div>
            </div>
            
            <h3><span class="emoji">3ï¸âƒ£</span> Ø³Ø§ÛŒØ± Ø§Ù†ÙˆØ§Ø¹</h3>
            
            <table>
                <thead>
                    <tr>
                        <th>Ù†ÙˆØ¹</th>
                        <th>Ú©Ø§Ø±Ø¨Ø±Ø¯</th>
                        <th>Ù…Ø«Ø§Ù„</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Image Embeddings</strong></td>
                        <td>ØªØµØ§ÙˆÛŒØ±</td>
                        <td>ResNet, VGG, CLIP</td>
                    </tr>
                    <tr>
                        <td><strong>Audio Embeddings</strong></td>
                        <td>ØµØ¯Ø§ Ùˆ Ù…ÙˆØ³ÛŒÙ‚ÛŒ</td>
                        <td>Wav2Vec, AudioMAE</td>
                    </tr>
                    <tr>
                        <td><strong>Graph Embeddings</strong></td>
                        <td>Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ Ùˆ Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§</td>
                        <td>Node2Vec, GraphSAGE</td>
                    </tr>
                    <tr>
                        <td><strong>Multimodal Embeddings</strong></td>
                        <td>ØªØ±Ú©ÛŒØ¨ Ú†Ù†Ø¯ Ù†ÙˆØ¹</td>
                        <td>CLIP, DALL-E</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 4: Word2Vec -->
        <div class="slide">
            <div class="slide-number">4</div>
            <h2>ğŸ›ï¸ Word2Vec - Ø§ÙˆÙ„ÛŒÙ† Ù‚Ø¯Ù…</h2>
            
            <div class="definition box">
                <h3><span class="emoji">ğŸ“–</span> Word2Vec Ú†ÛŒØ³ØªØŸ</h3>
                <p>
                    ÛŒÚ© ØªÚ©Ù†ÛŒÚ© ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù‡ ØªÙˆØ³Ø· Google Ø¯Ø± Ø³Ø§Ù„ 2013 Ù…Ø¹Ø±ÙÛŒ Ø´Ø¯.
                    Ø§ØµÙ„ Ø§ØµÙ„ÛŒ: <strong>"Ú©Ù„Ù…Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø± Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø¸Ø§Ù‡Ø± Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ØŒ Ù…Ø¹Ø§Ù†ÛŒ Ù…Ø´Ø§Ø¨Ù‡ÛŒ Ø¯Ø§Ø±Ù†Ø¯"</strong>
                </p>
            </div>
            
            <h3><span class="emoji">ğŸ”§</span> Ø¯Ùˆ Ù…Ø¹Ù…Ø§Ø±ÛŒ Word2Vec</h3>
            
            <div class="comparison">
                <div class="info box">
                    <h4>CBOW (Continuous Bag of Words)</h4>
                    <p><strong>Ø§ÛŒØ¯Ù‡:</strong> Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ø·Ø±Ø§ÙØŒ Ú©Ù„Ù…Ù‡ ÙˆØ³Ø· Ø±Ø§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†</p>
                    <p><strong>Ù…Ø«Ø§Ù„:</strong></p>
                    <p>"Ù…Ù† [____] Ø®ÙˆØ±Ø¯Ù…" â†’ "ØºØ°Ø§"</p>
                    <p><strong>Ø³Ø±Ø¹Øª:</strong> Ø³Ø±ÛŒØ¹â€ŒØªØ±</p>
                    <p><strong>Ø¯Ù‚Øª:</strong> Ú©Ù„Ù…Ø§Øª Ù¾Ø±ØªÚ©Ø±Ø§Ø±</p>
                </div>
                
                <div class="warning box">
                    <h4>Skip-gram</h4>
                    <p><strong>Ø§ÛŒØ¯Ù‡:</strong> Ø§Ø² Ú©Ù„Ù…Ù‡ ÙˆØ³Ø·ØŒ Ú©Ù„Ù…Ø§Øª Ø§Ø·Ø±Ø§Ù Ø±Ø§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†</p>
                    <p><strong>Ù…Ø«Ø§Ù„:</strong></p>
                    <p>"ØºØ°Ø§" â†’ ["Ù…Ù†", "Ø®ÙˆØ±Ø¯Ù…"]</p>
                    <p><strong>Ø³Ø±Ø¹Øª:</strong> Ú©Ù†Ø¯ØªØ±</p>
                    <p><strong>Ø¯Ù‚Øª:</strong> Ú©Ù„Ù…Ø§Øª Ú©Ù…â€ŒØªÚ©Ø±Ø§Ø±</p>
                </div>
            </div>
            
            <h3><span class="emoji">ğŸ’»</span> Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Gensim</h3>
            
            <div class="example box">
                <h4>Ù…Ø«Ø§Ù„ 1: Ø¢Ù…ÙˆØ²Ø´ Word2Vec</h4>
                <div class="code">
from gensim.models import Word2Vec
from hazm import word_tokenize, Normalizer
# Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†
normalizer = Normalizer()
sentences = [
    "Ù…Ù† ÛŒÚ© Ø³Ú¯ Ú©ÙˆÚ†Ú© Ø¯Ø§Ø±Ù…",
    "Ø³Ú¯ Ù…Ù† Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù…Ø²Ù‡ Ø§Ø³Øª",
    "Ú¯Ø±Ø¨Ù‡ Ù…Ù† Ø³ÛŒØ§Ù‡ Ø§Ø³Øª",
    "Ú¯Ø±Ø¨Ù‡ Ùˆ Ø³Ú¯ Ø¯ÙˆØ³Øª Ù‡Ø³ØªÙ†Ø¯",
    "Ù…Ù† Ø­ÛŒÙˆØ§Ù†Ø§Øª Ø±Ø§ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…"
]

# Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ
tokenized_sentences = []
for sentence in sentences:
    normalized = normalizer.normalize(sentence)
    tokens = word_tokenize(normalized)
    tokenized_sentences.append(tokens)

print("Ø¬Ù…Ù„Ø§Øª ØªÙˆÚ©Ù† Ø´Ø¯Ù‡:")
for tokens in tokenized_sentences:
    print(tokens)

# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Word2Vec
model = Word2Vec(
    sentences=tokenized_sentences,
    vector_size=100,      # Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø±Ø¯Ø§Ø±
    window=5,              # Ù¾Ù†Ø¬Ø±Ù‡ context
    min_count=1,           # Ø­Ø¯Ø§Ù‚Ù„ ØªÚ©Ø±Ø§Ø±
    workers=4,             # ØªØ¹Ø¯Ø§Ø¯ Ù‡Ø³ØªÙ‡ CPU
    sg=0                   # 0=CBOW, 1=Skip-gram
)

# Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
model.save("word2vec_model.bin")
print("âœ… Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
                </div>
            </div>
            
            <div class="example box">
                <h4>Ù…Ø«Ø§Ù„ 2: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡</h4>
                <div class="code">
# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
model = Word2Vec.load("word2vec_model.bin")

# Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø±Ø¯Ø§Ø± ÛŒÚ© Ú©Ù„Ù…Ù‡
vector = model.wv['Ø³Ú¯']
print(f"Ø¨Ø±Ø¯Ø§Ø± Ú©Ù„Ù…Ù‡ 'Ø³Ú¯': {vector[:5]}...")
print(f"Ø·ÙˆÙ„ Ø¨Ø±Ø¯Ø§Ø±: {len(vector)}")

# ÛŒØ§ÙØªÙ† Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡
similar_words = model.wv.most_similar('Ø³Ú¯', topn=3)
print("\nğŸ” Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ù‡ 'Ø³Ú¯':")
for word, score in similar_words:
    print(f"  {word}: {score:.4f}")

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¨ÛŒÙ† Ø¯Ùˆ Ú©Ù„Ù…Ù‡
similarity = model.wv.similarity('Ø³Ú¯', 'Ú¯Ø±Ø¨Ù‡')
print(f"\nğŸ“Š Ø´Ø¨Ø§Ù‡Øª 'Ø³Ú¯' Ùˆ 'Ú¯Ø±Ø¨Ù‡': {similarity:.4f}")

# Ø¹Ù…Ù„ÛŒØ§Øª Ø¬Ø¨Ø±ÛŒ Ø±ÙˆÛŒ Ú©Ù„Ù…Ø§Øª
# Ù¾Ø§Ø¯Ø´Ø§Ù‡ - Ù…Ø±Ø¯ + Ø²Ù† = Ù…Ù„Ú©Ù‡
result = model.wv.most_similar(
    positive=['Ø³Ú¯', 'Ø¨Ø§Ù…Ø²Ù‡'],
    negative=['Ø¨Ø¯'],
    topn=1
)
print(f"\nğŸ§® Ø³Ú¯ + Ø¨Ø§Ù…Ø²Ù‡ - Ø¨Ø¯ = {result[0][0]}")

# Ú†Ú© Ú©Ø±Ø¯Ù† ÙˆØ¬ÙˆØ¯ Ú©Ù„Ù…Ù‡
if 'Ø³Ú¯' in model.wv:
    print("âœ… Ú©Ù„Ù…Ù‡ 'Ø³Ú¯' Ø¯Ø± Ù…Ø¯Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯")
                </div>
            </div>
            
            <div class="key-point box">
                <h3><span class="emoji">âš™ï¸</span> Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ù‡Ù… Word2Vec</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Ù¾Ø§Ø±Ø§Ù…ØªØ±</th>
                            <th>ØªÙˆØ¶ÛŒØ­</th>
                            <th>Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>vector_size</strong></td>
                            <td>Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø±Ø¯Ø§Ø± (Ø§Ø¨Ø¹Ø§Ø¯)</td>
                            <td>100-300</td>
                        </tr>
                        <tr>
                            <td><strong>window</strong></td>
                            <td>Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù¾Ù†Ø¬Ø±Ù‡ context</td>
                            <td>5-10</td>
                        </tr>
                        <tr>
                            <td><strong>min_count</strong></td>
                            <td>Ø­Ø¯Ø§Ù‚Ù„ ØªÚ©Ø±Ø§Ø± Ú©Ù„Ù…Ù‡</td>
                            <td>5</td>
                        </tr>
                        <tr>
                            <td><strong>sg</strong></td>
                            <td>0=CBOW, 1=Skip-gram</td>
                            <td>0 (Ø³Ø±ÛŒØ¹â€ŒØªØ±)</td>
                        </tr>
                        <tr>
                            <td><strong>epochs</strong></td>
                            <td>ØªØ¹Ø¯Ø§Ø¯ Ø¯ÙˆØ± Ø¢Ù…ÙˆØ²Ø´</td>
                            <td>5-100</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 5: OpenAI Embeddings -->
        <div class="slide">
            <div class="slide-number">5</div>
            <h2>ğŸš€ OpenAI Embeddings - Ù…Ø¯Ø±Ù† Ùˆ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯</h2>
            
            <div class="highlight box">
                <h3><span class="emoji">ğŸŒŸ</span> OpenAI Embeddings Ú†ÛŒØ³ØªØŸ</h3>
                <p style="font-size: 1.3em;">
                    Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ OpenAI Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ù…ØªÙ†ØŒ Ú©Ø¯ØŒ Ùˆ Ø­ØªÛŒ Ø¬Ù…Ù„Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø±Ø§ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ 
                    Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ù†Ø¯. Ø§ÛŒÙ† Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ <strong>Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ</strong> Ùˆ 
                    <strong>Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ RAG</strong> Ø¹Ø§Ù„ÛŒ Ù‡Ø³ØªÙ†Ø¯.
                </p>
            </div>
            
            <h3><span class="emoji">ğŸ“Š</span> Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯</h3>
            
            <table>
                <thead>
                    <tr>
                        <th>Ù…Ø¯Ù„</th>
                        <th>Ø§Ø¨Ø¹Ø§Ø¯</th>
                        <th>Ù‡Ø²ÛŒÙ†Ù‡ (Ù‡Ø± 1M ØªÙˆÚ©Ù†)</th>
                        <th>Ú©Ø§Ø±Ø¨Ø±Ø¯</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>text-embedding-3-small</strong></td>
                        <td>1536</td>
                        <td>$0.02</td>
                        <td>Ø³Ø±ÛŒØ¹ Ùˆ Ø§Ø±Ø²Ø§Ù†</td>
                    </tr>
                    <tr>
                        <td><strong>text-embedding-3-large</strong></td>
                        <td>3072</td>
                        <td>$0.13</td>
                        <td>Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±</td>
                    </tr>
                    <tr>
                        <td><strong>text-embedding-ada-002</strong></td>
                        <td>1536</td>
                        <td>$0.10</td>
                        <td>Ù†Ø³Ø®Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ</td>
                    </tr>
                </tbody>
            </table>
            
            <div class="example box">
                <h3><span class="emoji">ğŸ’»</span> Ù…Ø«Ø§Ù„ 1: ØªÙˆÙ„ÛŒØ¯ Embedding Ø³Ø§Ø¯Ù‡</h3>
                <div class="code">
from openai import OpenAI
import numpy as np

# Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù„Ø§ÛŒÙ†Øª
client = OpenAI(api_key="your-api-key")

# ØªÙˆÙ„ÛŒØ¯ embedding Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù…ØªÙ†
def get_embedding(text, model="text-embedding-3-small"):
    """ØªÙˆÙ„ÛŒØ¯ embedding Ø¨Ø±Ø§ÛŒ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ"""
    text = text.replace("\n", " ")
    response = client.embeddings.create(
        input=[text],
        model=model
    )
    return response.data[0].embedding

# Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡
text = "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ Ø§Ø³Øª"
embedding = get_embedding(text)

print(f"ğŸ“ Ø·ÙˆÙ„ Ø¨Ø±Ø¯Ø§Ø±: {len(embedding)}")
print(f"ğŸ”¢ Ù¾Ù†Ø¬ Ø¹Ø¯Ø¯ Ø§ÙˆÙ„: {embedding[:5]}")
print(f"ğŸ“Š Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡: {type(embedding)}")

# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ numpy array
embedding_array = np.array(embedding)
print(f"\nâœ… Embedding ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {embedding_array.shape}")
                </div>
            </div>
            
            <div class="example box">
                <h3><span class="emoji">ğŸ”</span> Ù…Ø«Ø§Ù„ 2: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ù…Ø¹Ù†Ø§ÛŒÛŒ</h3>
                <div class="code">
from sklearn.metrics.pairwise import cosine_similarity

# ØªÙˆÙ„ÛŒØ¯ embedding Ø¨Ø±Ø§ÛŒ Ú†Ù†Ø¯ Ù…ØªÙ†
texts = [
    "Ù…Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø±Ø§ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…",
    "Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø¹Ù„Ø§Ù‚Ù‡ Ù…Ù† Ø§Ø³Øª",
    "Ù…Ù† ØºØ°Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…",
    "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ø§Ø³Øª"
]

# ØªÙˆÙ„ÛŒØ¯ embeddings
embeddings = []
for text in texts:
    emb = get_embedding(text)
    embeddings.append(emb)

# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ numpy array
embeddings_array = np.array(embeddings)

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø´Ø¨Ø§Ù‡Øª
similarity_matrix = cosine_similarity(embeddings_array)

# Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
print("ğŸ“Š Ù…Ø§ØªØ±ÛŒØ³ Ø´Ø¨Ø§Ù‡Øª:\n")
for i, text1 in enumerate(texts):
    for j, text2 in enumerate(texts):
        if i < j:
            score = similarity_matrix[i][j]
            print(f"\n'{text1}'")
            print(f"  â†” '{text2}'")
            print(f"  Ø´Ø¨Ø§Ù‡Øª: {score:.4f}")

# Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø«Ø§Ù„:
# 'Ù…Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø±Ø§ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…'
#   â†” 'Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø¹Ù„Ø§Ù‚Ù‡ Ù…Ù† Ø§Ø³Øª'
#   Ø´Ø¨Ø§Ù‡Øª: 0.8934  â† Ø´Ø¨Ø§Ù‡Øª Ø¨Ø§Ù„Ø§!
                </div>
            </div>
            
            <div class="example box">
                <h3><span class="emoji">ğŸ”</span> Ù…Ø«Ø§Ù„ 3: Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ</h3>
                <div class="code">
def semantic_search(query, documents, top_k=3):
    """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¯Ø± Ø§Ø³Ù†Ø§Ø¯"""
    
    # ØªÙˆÙ„ÛŒØ¯ embedding Ø¨Ø±Ø§ÛŒ query
    query_embedding = get_embedding(query)
    
    # ØªÙˆÙ„ÛŒØ¯ embeddings Ø¨Ø±Ø§ÛŒ Ø§Ø³Ù†Ø§Ø¯
    doc_embeddings = []
    for doc in documents:
        emb = get_embedding(doc)
        doc_embeddings.append(emb)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª
    similarities = cosine_similarity(
        [query_embedding],
        doc_embeddings
    )[0]
    
    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ top_k
    top_indices = np.argsort(similarities)[::-1][:top_k]
    
    # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
    results = []
    for idx in top_indices:
        results.append({
            'document': documents[idx],
            'score': similarities[idx]
        })
    
    return results

# Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡
documents = [
    "Python ÛŒÚ© Ø²Ø¨Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ù…Ø­Ø¨ÙˆØ¨ Ø§Ø³Øª",
    "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø­Ø§Ù„ ØªØºÛŒÛŒØ± Ø¯Ù†ÛŒØ§ Ø§Ø³Øª",
    "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡ AI Ø§Ø³Øª",
    "ØºØ°Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø¨Ø³ÛŒØ§Ø± Ø®ÙˆØ´Ù…Ø²Ù‡ Ø§Ø³Øª",
    "Django ÛŒÚ© ÙØ±ÛŒÙ…ÙˆØ±Ú© ÙˆØ¨ Ù¾Ø§ÛŒØªÙˆÙ† Ø§Ø³Øª"
]

query = "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø¨Ø§ Ù¾Ø§ÛŒØªÙˆÙ†"
results = semantic_search(query, documents)

print(f"ğŸ” Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ: '{query}'\n")
for i, result in enumerate(results, 1):
    print(f"{i}. {result['document']}")
    print(f"   Ø§Ù…ØªÛŒØ§Ø²: {result['score']:.4f}\n")
                </div>
            </div>
            
            <div class="warning box">
                <h3><span class="emoji">âš ï¸</span> Ù†Ú©Ø§Øª Ù…Ù‡Ù…</h3>
                <ul>
                    <li><strong>Ù‡Ø²ÛŒÙ†Ù‡:</strong> Ù‡Ø± ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API Ù‡Ø²ÛŒÙ†Ù‡ Ø¯Ø§Ø±Ø¯</li>
                    <li><strong>Rate Limit:</strong> Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± Ø¯Ù‚ÛŒÙ‚Ù‡</li>
                    <li><strong>Cache:</strong> embeddings Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒØ¯ ØªØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´ÙˆÙ†Ø¯</li>
                    <li><strong>Batch:</strong> Ú†Ù†Ø¯ Ù…ØªÙ† Ø±Ø§ Ù‡Ù…Ø²Ù…Ø§Ù† Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ (ØªØ§ 2048 Ù…ØªÙ†)</li>
                </ul>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 6: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª -->
        <div class="slide">
            <div class="slide-number">6</div>
            <h2>ğŸ“ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¨ÛŒÙ† Embeddings</h2>
            
            <div class="definition box">
                <h3><span class="emoji">ğŸ¯</span> Ø´Ø¨Ø§Ù‡Øª Ú†ÛŒØ³ØªØŸ</h3>
                <p>
                    Ø´Ø¨Ø§Ù‡Øª ÛŒØ¹Ù†ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¯Ùˆ Ø¨Ø±Ø¯Ø§Ø± Ú†Ù‚Ø¯Ø± Ø¨Ù‡ Ù‡Ù… Ù†Ø²Ø¯ÛŒÚ© Ù‡Ø³ØªÙ†Ø¯. 
                    Ù‡Ø±Ú†Ù‡ Ø¯Ùˆ Ø¨Ø±Ø¯Ø§Ø± Ø¨Ù‡ Ù‡Ù… Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ± Ø¨Ø§Ø´Ù†Ø¯ØŒ Ù…Ø¹Ù†Ø§ÛŒ Ø¢Ù†â€ŒÙ‡Ø§ Ù…Ø´Ø§Ø¨Ù‡â€ŒØªØ± Ø§Ø³Øª.
                </p>
            </div>
            
            <h3><span class="emoji">ğŸ“Š</span> Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª</h3>
            
            <div class="grid">
                <div class="card">
                    <h4>1ï¸âƒ£ Cosine Similarity</h4>
                    <p><strong>Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† Ø±ÙˆØ´</strong></p>
                    <p>Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ø§ÙˆÛŒÙ‡ Ø¨ÛŒÙ† Ø¯Ùˆ Ø¨Ø±Ø¯Ø§Ø±</p>
                    <p><strong>Ù…Ø­Ø¯ÙˆØ¯Ù‡:</strong> -1 ØªØ§ +1</p>
                    <p><strong>+1:</strong> Ú©Ø§Ù…Ù„Ø§Ù‹ Ù…Ø´Ø§Ø¨Ù‡</p>
                    <p><strong>0:</strong> Ø¨Ø¯ÙˆÙ† Ø§Ø±ØªØ¨Ø§Ø·</p>
                    <p><strong>-1:</strong> Ú©Ø§Ù…Ù„Ø§Ù‹ Ù…Ø®Ø§Ù„Ù</p>
                </div>
                
                <div class="card">
                    <h4>2ï¸âƒ£ Euclidean Distance</h4>
                    <p><strong>ÙØ§ØµÙ„Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ…</strong></p>
                    <p>ÙØ§ØµÙ„Ù‡ Ø®Ø· Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨ÛŒÙ† Ø¯Ùˆ Ù†Ù‚Ø·Ù‡</p>
                    <p><strong>Ù…Ø­Ø¯ÙˆØ¯Ù‡:</strong> 0 ØªØ§ âˆ</p>
                    <p><strong>0:</strong> ÛŒÚ©Ø³Ø§Ù†</p>
                    <p><strong>Ø¨Ø²Ø±Ú¯:</strong> Ù…ØªÙØ§ÙˆØª</p>
                </div>
                
                <div class="card">
                    <h4>3ï¸âƒ£ Dot Product</h4>
                    <p><strong>Ø¶Ø±Ø¨ Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ</strong></p>
                    <p>Ø­Ø§ØµÙ„â€ŒØ¶Ø±Ø¨ Ø§Ø¹Ø¶Ø§ÛŒ Ù…ØªÙ†Ø§Ø¸Ø±</p>
                    <p><strong>Ù…Ø­Ø¯ÙˆØ¯Ù‡:</strong> -âˆ ØªØ§ +âˆ</p>
                    <p><strong>Ø¨Ø²Ø±Ú¯:</strong> Ù…Ø´Ø§Ø¨Ù‡</p>
                    <p><strong>Ú©ÙˆÚ†Ú©:</strong> Ù…ØªÙØ§ÙˆØª</p>
                </div>
            </div>
            
            <h3><span class="emoji">ğŸ§®</span> ÙØ±Ù…ÙˆÙ„â€ŒÙ‡Ø§</h3>
            
            <div class="math-formula">
                <strong>Cosine Similarity:</strong><br><br>
                similarity = (A Â· B) / (||A|| Ã— ||B||)
            </div>
            
            <div class="math-formula">
                <strong>Euclidean Distance:</strong><br><br>
                distance = âˆš(Î£(Aáµ¢ - Báµ¢)Â²)
            </div>
            
            <div class="math-formula">
                <strong>Dot Product:</strong><br><br>
                dot_product = Î£(Aáµ¢ Ã— Báµ¢)
            </div>
            
            <div class="example box">
                <h3><span class="emoji">ğŸ’»</span> Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø± Python</h3>
                <div class="code">
import numpy as np
from sklearn.metrics.pairwise import (
    cosine_similarity,
    euclidean_distances
)

# Ø¯Ùˆ Ø¨Ø±Ø¯Ø§Ø± Ù†Ù…ÙˆÙ†Ù‡
vector_a = np.array([1, 2, 3, 4, 5])
vector_b = np.array([2, 3, 4, 5, 6])
vector_c = np.array([10, 20, 30, 40, 50])

# 1. Cosine Similarity
cos_sim_ab = cosine_similarity([vector_a], [vector_b])[0][0]
cos_sim_ac = cosine_similarity([vector_a], [vector_c])[0][0]

print("ğŸ“Š Cosine Similarity:")
print(f"  A â†” B: {cos_sim_ab:.4f}")
print(f"  A â†” C: {cos_sim_ac:.4f}")

# 2. Euclidean Distance
euc_dist_ab = euclidean_distances([vector_a], [vector_b])[0][0]
euc_dist_ac = euclidean_distances([vector_a], [vector_c])[0][0]

print("\nğŸ“ Euclidean Distance:")
print(f"  A â†” B: {euc_dist_ab:.4f}")
print(f"  A â†” C: {euc_dist_ac:.4f}")

# 3. Dot Product
dot_ab = np.dot(vector_a, vector_b)
dot_ac = np.dot(vector_a, vector_c)

print("\nğŸ”¢ Dot Product:")
print(f"  A Â· B: {dot_ab}")
print(f"  A Â· C: {dot_ac}")

# Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÛŒ Cosine Similarity
def manual_cosine_similarity(a, b):
    dot_product = np.dot(a, b)
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    return dot_product / (norm_a * norm_b)

manual_cos = manual_cosine_similarity(vector_a, vector_b)
print(f"\nâœ… Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø³ØªÛŒ: {manual_cos:.4f}")
                </div>
            </div>
            
            <div class="similarity-demo">
                <h3 style="text-align: center; color: #667eea;"><span class="emoji">ğŸ¯</span> Ù†Ù…ÙˆÙ†Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ</h3>
                
                <div class="text-pair">
                    <p><strong>Ù…ØªÙ† 1:</strong> "Ù…Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø±Ø§ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…"</p>
                    <p><strong>Ù…ØªÙ† 2:</strong> "Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø¹Ù„Ø§Ù‚Ù‡ Ù…Ù† Ø§Ø³Øª"</p>
                    <span class="similarity-score">Ø´Ø¨Ø§Ù‡Øª: 0.89 â­â­â­â­â­</span>
                </div>
                
                <div class="text-pair">
                    <p><strong>Ù…ØªÙ† 1:</strong> "Ù…Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø±Ø§ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…"</p>
                    <p><strong>Ù…ØªÙ† 2:</strong> "Ù‡ÙˆØ§ Ø§Ù…Ø±ÙˆØ² Ø¢ÙØªØ§Ø¨ÛŒ Ø§Ø³Øª"</p>
                    <span class="similarity-score" style="background: #f44336;">Ø´Ø¨Ø§Ù‡Øª: 0.12 â­</span>
                </div>
                
                <div class="text-pair">
                    <p><strong>Ù…ØªÙ† 1:</strong> "Ø³Ú¯ ÛŒÚ© Ø­ÛŒÙˆØ§Ù† Ø®Ø§Ù†Ú¯ÛŒ Ø§Ø³Øª"</p>
                    <p><strong>Ù…ØªÙ† 2:</strong> "Ú¯Ø±Ø¨Ù‡ ÛŒÚ© Ø­ÛŒÙˆØ§Ù† Ø®Ø§Ù†Ú¯ÛŒ Ø§Ø³Øª"</p>
                    <span class="similarity-score" style="background: #ff9800;">Ø´Ø¨Ø§Ù‡Øª: 0.76 â­â­â­â­</span>
                </div>
            </div>
            
            <div class="key-point box">
                <h3><span class="emoji">ğŸ’¡</span> Ú©Ø¯Ø§Ù… Ø±ÙˆØ´ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒÙ…ØŸ</h3>
                <ul>
                    <li><strong>Cosine Similarity:</strong> Ø¨Ø±Ø§ÛŒ Ø§Ú©Ø«Ø± Ù…ÙˆØ§Ø±Ø¯ (ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯) âœ…</li>
                    <li><strong>Euclidean Distance:</strong> ÙˆÙ‚ØªÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø±Ø¯Ø§Ø± Ù…Ù‡Ù… Ø§Ø³Øª</li>
                    <li><strong>Dot Product:</strong> Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ normalized</li>
                </ul>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 7: Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ -->
        <div class="slide">
            <div class="slide-number">7</div>
            <h2>ğŸ¯ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Embeddings</h2>
            
            <h3><span class="emoji">1ï¸âƒ£</span> Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ (Semantic Search)</h3>
            
            <div class="info box">
                <h4>Ù…ÙÙ‡ÙˆÙ…</h4>
                <p>
                    Ø¨Ù‡ Ø¬Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ú©Ù„Ù…Ù‡ Ø¨Ù‡ Ú©Ù„Ù…Ù‡ØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ <strong>Ù…Ø¹Ù†Ø§</strong> Ø¬Ø³ØªØ¬Ùˆ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
                    Ú©Ø§Ø±Ø¨Ø± "Ù…Ø§Ø´ÛŒÙ† Ø³Ø±ÛŒØ¹" Ø¬Ø³ØªØ¬Ùˆ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ù†ØªØ§ÛŒØ¬ "Ø§ØªÙˆÙ…Ø¨ÛŒÙ„ ØªÙ†Ø¯Ø±Ùˆ" Ù‡Ù… Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
                </p>
            </div>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ</h4>
                <div class="code">
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI

client = OpenAI(api_key="your-api-key")

class SemanticSearch:
    def __init__(self):
        self.documents = []
        self.embeddings = []
    
    def add_documents(self, docs):
        """Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø³Ù†Ø§Ø¯ Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡"""
        for doc in docs:
            self.documents.append(doc)
            # ØªÙˆÙ„ÛŒØ¯ embedding
            emb = self.get_embedding(doc)
            self.embeddings.append(emb)
        print(f"âœ… {len(docs)} Ø³Ù†Ø¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯")
    
    def get_embedding(self, text):
        """ØªÙˆÙ„ÛŒØ¯ embedding"""
        response = client.embeddings.create(
            input=[text],
            model="text-embedding-3-small"
        )
        return response.data[0].embedding
    
    def search(self, query, top_k=3):
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ"""
        # ØªÙˆÙ„ÛŒØ¯ embedding Ø¨Ø±Ø§ÛŒ query
        query_emb = self.get_embedding(query)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¨Ø§ ØªÙ…Ø§Ù… Ø§Ø³Ù†Ø§Ø¯
        similarities = cosine_similarity(
            [query_emb],
            self.embeddings
        )[0]
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ top_k
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            results.append({
                'document': self.documents[idx],
                'score': float(similarities[idx])
            })
        
        return results

# Ø§Ø³ØªÙØ§Ø¯Ù‡
search_engine = SemanticSearch()

# Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø³Ù†Ø§Ø¯
documents = [
    "Python ÛŒÚ© Ø²Ø¨Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø§Ø³Øª",
    "Django ÙØ±ÛŒÙ…ÙˆØ±Ú© ÙˆØ¨ Ù¾Ø§ÛŒØªÙˆÙ† Ø§Ø³Øª",
    "Machine Learning Ø¨Ø§ Python",
    "Ø¢Ù…ÙˆØ²Ø´ Ù¾Ø®Øª ØºØ°Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ",
    "ØªØ§Ø±ÛŒØ® Ø§ÛŒØ±Ø§Ù† Ø¨Ø§Ø³ØªØ§Ù†"
]
search_engine.add_documents(documents)

# Ø¬Ø³ØªØ¬Ùˆ
query = "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ"
results = search_engine.search(query)

print(f"\nğŸ” Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ: '{query}'\n")
for i, result in enumerate(results, 1):
    print(f"{i}. {result['document']}")
    print(f"   Ø§Ù…ØªÛŒØ§Ø²: {result['score']:.4f}\n")
                </div>
            </div>
            
            <h3><span class="emoji">2ï¸âƒ£</span> Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡ (Recommendation System)</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> ØªÙˆØµÛŒÙ‡ Ù…Ø­ØµÙˆÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªÙˆØ¶ÛŒØ­Ø§Øª</h4>
                <div class="code">
class ProductRecommender:
    def __init__(self):
        self.products = []
        self.embeddings = []
    
    def add_product(self, product_id, name, description):
        """Ø§ÙØ²ÙˆØ¯Ù† Ù…Ø­ØµÙˆÙ„"""
        product = {
            'id': product_id,
            'name': name,
            'description': description
        }
        self.products.append(product)
        
        # ØªÙˆÙ„ÛŒØ¯ embedding Ø§Ø² Ù†Ø§Ù… + ØªÙˆØ¶ÛŒØ­Ø§Øª
        text = f"{name} {description}"
        emb = self.get_embedding(text)
        self.embeddings.append(emb)
    
    def get_embedding(self, text):
        response = client.embeddings.create(
            input=[text],
            model="text-embedding-3-small"
        )
        return response.data[0].embedding
    
    def recommend(self, product_id, top_k=3):
        """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡"""
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ†Ø¯Ú©Ø³ Ù…Ø­ØµÙˆÙ„
        idx = None
        for i, product in enumerate(self.products):
            if product['id'] == product_id:
                idx = i
                break
        
        if idx is None:
            return []
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª
        product_emb = self.embeddings[idx]
        similarities = cosine_similarity(
            [product_emb],
            self.embeddings
        )[0]
        
        # Ø­Ø°Ù Ø®ÙˆØ¯ Ù…Ø­ØµÙˆÙ„
        similarities[idx] = -1
        
        # Ø§Ù†ØªØ®Ø§Ø¨ top_k
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        recommendations = []
        for i in top_indices:
            recommendations.append({
                'product': self.products[i],
                'score': float(similarities[i])
            })
        
        return recommendations

# Ø§Ø³ØªÙØ§Ø¯Ù‡
recommender = ProductRecommender()

# Ø§ÙØ²ÙˆØ¯Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª
recommender.add_product(
    1, 
    "Ù„Ù¾ØªØ§Ù¾ Ú¯ÛŒÙ…ÛŒÙ†Ú¯",
    "Ù„Ù¾ØªØ§Ù¾ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒ Ø¨Ø§ Ú©Ø§Ø±Øª Ú¯Ø±Ø§ÙÛŒÚ© RTX"
)
recommender.add_product(
    2,
    "Ù…ÙˆØ³ Ú¯ÛŒÙ…ÛŒÙ†Ú¯",
    "Ù…ÙˆØ³ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒ Ø¨Ø§ DPI Ø¨Ø§Ù„Ø§"
)
recommender.add_product(
    3,
    "Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù…Ú©Ø§Ù†ÛŒÚ©ÛŒ",
    "ØµÙØ­Ù‡â€ŒÚ©Ù„ÛŒØ¯ Ù…Ú©Ø§Ù†ÛŒÚ©ÛŒ Ø¨Ø±Ø§ÛŒ Ú¯ÛŒÙ…Ø±Ù‡Ø§"
)
recommender.add_product(
    4,
    "Ú©ØªØ§Ø¨ Ø¢Ø´Ù¾Ø²ÛŒ",
    "Ø¢Ù…ÙˆØ²Ø´ Ù¾Ø®Øª ØºØ°Ø§Ù‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ"
)

# ØªÙˆØµÛŒÙ‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡
recommendations = recommender.recommend(1, top_k=2)

print("ğŸ¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:\n")
for rec in recommendations:
    print(f"- {rec['product']['name']}")
    print(f"  Ø´Ø¨Ø§Ù‡Øª: {rec['score']:.4f}\n")
                </div>
            </div>
            
            <h3><span class="emoji">3ï¸âƒ£</span> Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ØªÙ† (Text Classification)</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…ØªÙˆÙ†</h4>
                <div class="code">
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ
texts = [
    "Ø§ÛŒÙ† ÙÛŒÙ„Ù… ÙˆØ§Ù‚Ø¹Ø§ Ø¹Ø§Ù„ÛŒ Ø¨ÙˆØ¯",
    "Ø¨Ø§Ø²ÛŒ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨ÙˆØ¯",
    "Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø§ÙØªØ¶Ø§Ø­ Ø§Ø³Øª",
    "Ø®ÛŒÙ„ÛŒ Ø¨Ø¯ Ø¨ÙˆØ¯ Ùˆ Ù¾ÙˆÙ„â€ŒÙ…Ø§Ù† Ù‡Ø¯Ø± Ø±ÙØª",
    "Ø¹Ø§Ù„ÛŒ Ø¨ÙˆØ¯ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ù…",
    "Ø§ØµÙ„Ø§ Ø®ÙˆØ¨ Ù†Ø¨ÙˆØ¯"
]

labels = [1, 1, 0, 0, 1, 0]  # 1=Ù…Ø«Ø¨ØªØŒ 0=Ù…Ù†ÙÛŒ

# ØªÙˆÙ„ÛŒØ¯ embeddings
embeddings = []
for text in texts:
    response = client.embeddings.create(
        input=[text],
        model="text-embedding-3-small"
    )
    emb = response.data[0].embedding
    embeddings.append(emb)

X = np.array(embeddings)
y = np.array(labels)

# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
clf = LogisticRegression()
clf.fit(X, y)

# ØªØ³Øª
test_texts = [
    "Ø§ÛŒÙ† Ø±Ø³ØªÙˆØ±Ø§Ù† ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ø§Ø³Øª",
    "Ø®ÛŒÙ„ÛŒ Ø¨Ø¯ Ùˆ Ú¯Ø±Ø§Ù† Ø¨ÙˆØ¯"
]

for text in test_texts:
    # ØªÙˆÙ„ÛŒØ¯ embedding
    response = client.embeddings.create(
        input=[text],
        model="text-embedding-3-small"
    )
    emb = response.data[0].embedding
    
    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    prediction = clf.predict([emb])[0]
    proba = clf.predict_proba([emb])[0]
    
    sentiment = "Ù…Ø«Ø¨Øª ğŸ˜Š" if prediction == 1 else "Ù…Ù†ÙÛŒ ğŸ˜"
    confidence = max(proba) * 100
    
    print(f"\n'{text}'")
    print(f"Ø§Ø­Ø³Ø§Ø³: {sentiment}")
    print(f"Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {confidence:.1f}%")
                </div>
            </div>
            
            <h3><span class="emoji">4ï¸âƒ£</span> Clustering - Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø³Ù†Ø§Ø¯</h4>
                <div class="code">
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Ø§Ø³Ù†Ø§Ø¯
documents = [
    "Python Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ",
    "Django ÙˆØ¨ ÙØ±ÛŒÙ…ÙˆØ±Ú©",
    "Machine Learning",
    "ØºØ°Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ",
    "Ø¢Ø´Ù¾Ø²ÛŒ Ùˆ Ù¾Ø®Øª",
    "Ú©Ø¨Ø§Ø¨ Ùˆ Ú†Ù„ÙˆÚ©Ø¨Ø§Ø¨",
    "ÙÙˆØªØ¨Ø§Ù„ Ùˆ ÙˆØ±Ø²Ø´",
    "Ø¨Ø³Ú©ØªØ¨Ø§Ù„ NBA"
]

# ØªÙˆÙ„ÛŒØ¯ embeddings
embeddings = []
for doc in documents:
    response = client.embeddings.create(
        input=[doc],
        model="text-embedding-3-small"
    )
    emb = response.data[0].embedding
    embeddings.append(emb)

X = np.array(embeddings)

# Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X)

# Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
print("ğŸ“Š Ù†ØªØ§ÛŒØ¬ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:\n")
for i in range(3):
    print(f"Ø®ÙˆØ´Ù‡ {i+1}:")
    cluster_docs = [documents[j] for j in range(len(documents)) 
                    if clusters[j] == i]
    for doc in cluster_docs:
        print(f"  - {doc}")
    print()

# Ø¨ØµØ±ÛŒâ€ŒØ³Ø§Ø²ÛŒ (Ú©Ø§Ù‡Ø´ Ø§Ø¨Ø¹Ø§Ø¯ Ø¨Ù‡ 2D)
pca = PCA(n_components=2)
X_2d = pca.fit_transform(X)

plt.figure(figsize=(10, 6))
plt.scatter(X_2d[:, 0], X_2d[:, 1], c=clusters, cmap='viridis')
for i, doc in enumerate(documents):
    plt.annotate(doc, (X_2d[i, 0], X_2d[i, 1]))
plt.title('Document Clustering')
plt.savefig('clustering.png')
print("âœ… Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø± clustering.png Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
                </div>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 8: Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ -->
        <div class="slide">
            <div class="slide-number">8</div>
            <h2>ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Embeddings</h2>
            
            <div class="warning box">
                <h3><span class="emoji">âš ï¸</span> Ú†Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù‡Ù… Ø§Ø³ØªØŸ</h3>
                <ul>
                    <li><strong>Ù‡Ø²ÛŒÙ†Ù‡:</strong> ØªÙˆÙ„ÛŒØ¯ embedding Ù‡Ø²ÛŒÙ†Ù‡ Ø¯Ø§Ø±Ø¯</li>
                    <li><strong>Ø²Ù…Ø§Ù†:</strong> Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¬Ø¯Ø¯ ÙˆÙ‚Øªâ€ŒÚ¯ÛŒØ± Ø§Ø³Øª</li>
                    <li><strong>Ú©Ø§Ø±Ø§ÛŒÛŒ:</strong> Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø² Ø¯ÛŒØ³Ú© Ø¨Ø³ÛŒØ§Ø± Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø§Ø³Øª</li>
                </ul>
            </div>
            
            <h3><span class="emoji">1ï¸âƒ£</span> Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø§ NumPy</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ .npy</h4>
                <div class="code">
import numpy as np
import json

# ØªÙˆÙ„ÛŒØ¯ embeddings
documents = [
    "Ù…ØªÙ† Ø§ÙˆÙ„",
    "Ù…ØªÙ† Ø¯ÙˆÙ…",
    "Ù…ØªÙ† Ø³ÙˆÙ…"
]

embeddings = []
for doc in documents:
    response = client.embeddings.create(
        input=[doc],
        model="text-embedding-3-small"
    )
    emb = response.data[0].embedding
    embeddings.append(emb)

embeddings_array = np.array(embeddings)

# Ø°Ø®ÛŒØ±Ù‡ embeddings
np.save('embeddings.npy', embeddings_array)

# Ø°Ø®ÛŒØ±Ù‡ Ù…ØªÙˆÙ† (Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø¬Ø¹)
with open('documents.json', 'w', encoding='utf-8') as f:
    json.dump(documents, f, ensure_ascii=False)

print("âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
loaded_embeddings = np.load('embeddings.npy')
with open('documents.json', 'r', encoding='utf-8') as f:
    loaded_documents = json.load(f)

print(f"âœ… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {loaded_embeddings.shape}")
                </div>
            </div>
            
            <h3><span class="emoji">2ï¸âƒ£</span> Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø§ Pickle</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Ø°Ø®ÛŒØ±Ù‡ Ø³Ø§Ø®ØªØ§Ø± Ú©Ø§Ù…Ù„</h4>
                <div class="code">
import pickle

# Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ù…Ù„
data = {
    'documents': documents,
    'embeddings': embeddings_array,
    'model': 'text-embedding-3-small',
    'created_at': '2024-01-01'
}

# Ø°Ø®ÛŒØ±Ù‡
with open('embeddings.pkl', 'wb') as f:
    pickle.dump(data, f)

print("âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¨Ø§ pickle")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
with open('embeddings.pkl', 'rb') as f:
    loaded_data = pickle.load(f)

print(f"âœ… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
print(f"Ù…Ø¯Ù„: {loaded_data['model']}")
print(f"ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯: {len(loaded_data['documents'])}")
                </div>
            </div>
            
            <h3><span class="emoji">3ï¸âƒ£</span> Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SQLite</h4>
                <div class="code">
import sqlite3

# Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
conn = sqlite3.connect('embeddings.db')
cursor = conn.cursor()

# Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„
cursor.execute('''
    CREATE TABLE IF NOT EXISTS embeddings (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        document TEXT NOT NULL,
        embedding BLOB NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
''')

# Ø¯Ø±Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
for doc, emb in zip(documents, embeddings):
    # ØªØ¨Ø¯ÛŒÙ„ embedding Ø¨Ù‡ bytes
    emb_bytes = np.array(emb).tobytes()
    cursor.execute(
        'INSERT INTO embeddings (document, embedding) VALUES (?, ?)',
        (doc, emb_bytes)
    )

conn.commit()
print("âœ… Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± database")

# Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ
cursor.execute('SELECT document, embedding FROM embeddings')
rows = cursor.fetchall()

for row in rows:
    doc = row[0]
    emb = np.frombuffer(row[1], dtype=np.float64)
    print(f"Ø³Ù†Ø¯: {doc}, Ø·ÙˆÙ„ embedding: {len(emb)}")

conn.close()
                </div>
            </div>
            
            <h3><span class="emoji">4ï¸âƒ£</span> Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Vector Database</h3>
            
            <div class="info box">
                <h4>Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ù…Ø­Ø¨ÙˆØ¨</h4>
                <ul>
                    <li><strong>Pinecone:</strong> Ø§Ø¨Ø±ÛŒØŒ Ø³Ø±ÛŒØ¹ØŒ Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±</li>
                    <li><strong>Weaviate:</strong> Ù…ØªÙ†â€ŒØ¨Ø§Ø²ØŒ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯</li>
                    <li><strong>Qdrant:</strong> Ø³Ø±ÛŒØ¹ØŒ Rust</li>
                    <li><strong>Milvus:</strong> Ù…Ù‚ÛŒØ§Ø³ Ø¨Ø²Ø±Ú¯</li>
                    <li><strong>ChromaDB:</strong> Ø³Ø§Ø¯Ù‡ØŒ Ù…Ø­Ù„ÛŒ</li>
                    <li><strong>FAISS:</strong> FacebookØŒ Ø³Ø±ÛŒØ¹</li>
                </ul>
            </div>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Ù…Ø«Ø§Ù„ Ø¨Ø§ ChromaDB</h4>
                <div class="code">
import chromadb

# Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„Ø§ÛŒÙ†Øª
client = chromadb.Client()

# Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§ Ø¯Ø±ÛŒØ§ÙØª collection
collection = client.create_collection(name="my_embeddings")

# Ø§ÙØ²ÙˆØ¯Ù† embeddings
collection.add(
    embeddings=embeddings,
    documents=documents,
    ids=[f"id{i}" for i in range(len(documents))]
)

print("âœ… Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ChromaDB")

# Ø¬Ø³ØªØ¬Ùˆ
query = "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ"
query_embedding = get_embedding(query)

results = collection.query(
    query_embeddings=[query_embedding],
    n_results=2
)

print("\nğŸ” Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ:")
for doc in results['documents'][0]:
    print(f"  - {doc}")
                </div>
            </div>
            
            <div class="key-point box">
                <h3><span class="emoji">ğŸ’¡</span> ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§</h3>
                <ul>
                    <li><strong>Ù¾Ø±ÙˆÚ˜Ù‡ Ú©ÙˆÚ†Ú©:</strong> NumPy ÛŒØ§ Pickle</li>
                    <li><strong>Ù¾Ø±ÙˆÚ˜Ù‡ Ù…ØªÙˆØ³Ø·:</strong> SQLite ÛŒØ§ ChromaDB</li>
                    <li><strong>Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø²Ø±Ú¯:</strong> Pinecone ÛŒØ§ Weaviate</li>
                    <li><strong>Production:</strong> Vector Database Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ</li>
                </ul>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 9: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ -->
        <div class="slide">
            <div class="slide-number">9</div>
            <h2>âš¡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ù†Ú©Ø§Øª Ø¹Ù…Ù„ÛŒ</h2>
            
            <h3><span class="emoji">1ï¸âƒ£</span> Ú©Ø§Ù‡Ø´ Ù‡Ø²ÛŒÙ†Ù‡</h3>
            
            <div class="warning box">
                <h4><span class="emoji">ğŸ’°</span> Ù…Ø¯ÛŒØ±ÛŒØª Ù‡Ø²ÛŒÙ†Ù‡ API</h4>
                <ul>
                    <li>Embeddings Ø±Ø§ cache Ú©Ù†ÛŒØ¯</li>
                    <li>Ø§Ø² Ù…Ø¯Ù„ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (text-embedding-3-small)</li>
                    <li>Batch processing: Ú†Ù†Ø¯ Ù…ØªÙ† Ø±Ø§ Ù‡Ù…Ø²Ù…Ø§Ù† Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯</li>
                    <li>ÙÙ‚Ø· Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ embedding Ú©Ù†ÛŒØ¯</li>
                </ul>
            </div>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Caching Ø¨Ø§ functools</h4>
                <div class="code">
from functools import lru_cache
import hashlib

class EmbeddingCache:
    def __init__(self):
        self.cache = {}
    
    def get_embedding(self, text):
        # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„ÛŒØ¯ ÛŒÚ©ØªØ§
        key = hashlib.md5(text.encode()).hexdigest()
        
        # Ú†Ú© Ú©Ø±Ø¯Ù† cache
        if key in self.cache:
            print(f"âœ… Ø§Ø² cache: {text[:30]}...")
            return self.cache[key]
        
        # ØªÙˆÙ„ÛŒØ¯ embedding
        print(f"ğŸ”„ ØªÙˆÙ„ÛŒØ¯ Ø¬Ø¯ÛŒØ¯: {text[:30]}...")
        response = client.embeddings.create(
            input=[text],
            model="text-embedding-3-small"
        )
        embedding = response.data[0].embedding
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache
        self.cache[key] = embedding
        return embedding
    
    def save_cache(self, filename='embedding_cache.pkl'):
        import pickle
        with open(filename, 'wb') as f:
            pickle.dump(self.cache, f)
        print(f"âœ… Cache Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {len(self.cache)} Ø¢ÛŒØªÙ…")
    
    def load_cache(self, filename='embedding_cache.pkl'):
        import pickle
        try:
            with open(filename, 'rb') as f:
                self.cache = pickle.load(f)
            print(f"âœ… Cache Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {len(self.cache)} Ø¢ÛŒØªÙ…")
        except FileNotFoundError:
            print("âš ï¸ ÙØ§ÛŒÙ„ cache ÛŒØ§ÙØª Ù†Ø´Ø¯")

# Ø§Ø³ØªÙØ§Ø¯Ù‡
cache = EmbeddingCache()
cache.load_cache()

# Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø±: ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯
emb1 = cache.get_embedding("Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† ØªØ³Øª Ø§Ø³Øª")

# Ø¯ÙˆÙ…ÛŒÙ† Ø¨Ø§Ø±: Ø§Ø² cache
emb2 = cache.get_embedding("Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† ØªØ³Øª Ø§Ø³Øª")

cache.save_cache()
                </div>
            </div>
            
            <h3><span class="emoji">2ï¸âƒ£</span> Batch Processing</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ</h4>
                <div class="code">
def get_embeddings_batch(texts, batch_size=100):
    """ØªÙˆÙ„ÛŒØ¯ embedding Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øª Ù…ØªÙˆÙ†"""
    all_embeddings = []
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ batch Ù‡Ø§
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        
        print(f"ğŸ”„ Ù¾Ø±Ø¯Ø§Ø²Ø´ batch {i//batch_size + 1}...")
        
        # Ø§Ø±Ø³Ø§Ù„ batch
        response = client.embeddings.create(
            input=batch,
            model="text-embedding-3-small"
        )
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ embeddings
        batch_embeddings = [item.embedding for item in response.data]
        all_embeddings.extend(batch_embeddings)
    
    return all_embeddings

# Ù…Ø«Ø§Ù„: 250 Ù…ØªÙ†
texts = [f"Ù…ØªÙ† Ø´Ù…Ø§Ø±Ù‡ {i}" for i in range(250)]

import time
start = time.time()
embeddings = get_embeddings_batch(texts, batch_size=100)
end = time.time()

print(f"\nâœ… {len(embeddings)} embedding Ø¯Ø± {end-start:.2f} Ø«Ø§Ù†ÛŒÙ‡")
print(f"âš¡ Ø³Ø±Ø¹Øª: {len(embeddings)/(end-start):.1f} embedding/s")
                </div>
            </div>
            
            <h3><span class="emoji">3ï¸âƒ£</span> Ú©Ø§Ù‡Ø´ Ø§Ø¨Ø¹Ø§Ø¯</h3>
            
            <div class="info box">
                <h4>Ú†Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø§Ø¨Ø¹Ø§Ø¯ØŸ</h4>
                <ul>
                    <li>Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù… Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ</li>
                    <li>Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ø¬Ø³ØªØ¬Ùˆ</li>
                    <li>Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù RAM</li>
                    <li>Ø¨ØµØ±ÛŒâ€ŒØ³Ø§Ø²ÛŒ (2D ÛŒØ§ 3D)</li>
                </ul>
            </div>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> PCA Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø§Ø¨Ø¹Ø§Ø¯</h4>
                <div class="code">
from sklearn.decomposition import PCA

# embeddings Ø§ØµÙ„ÛŒ (1536 Ø¨Ø¹Ø¯ÛŒ)
original_embeddings = np.array(embeddings)
print(f"Ø§Ø¨Ø¹Ø§Ø¯ Ø§ØµÙ„ÛŒ: {original_embeddings.shape}")

# Ú©Ø§Ù‡Ø´ Ø¨Ù‡ 256 Ø¨Ø¹Ø¯
pca = PCA(n_components=256)
reduced_embeddings = pca.fit_transform(original_embeddings)

print(f"Ø§Ø¨Ø¹Ø§Ø¯ Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡: {reduced_embeddings.shape}")
print(f"ÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ø­ÙØ¸ Ø´Ø¯Ù‡: {pca.explained_variance_ratio_.sum():.2%}")

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù…
original_size = original_embeddings.nbytes / (1024 * 1024)
reduced_size = reduced_embeddings.nbytes / (1024 * 1024)

print(f"\nğŸ’¾ Ø­Ø¬Ù… Ø§ØµÙ„ÛŒ: {original_size:.2f} MB")
print(f"ğŸ’¾ Ø­Ø¬Ù… Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡: {reduced_size:.2f} MB")
print(f"ğŸ“‰ Ú©Ø§Ù‡Ø´: {(1 - reduced_size/original_size)*100:.1f}%")

# ØªØ³Øª Ø¯Ù‚Øª
from sklearn.metrics.pairwise import cosine_similarity

sim_original = cosine_similarity(
    [original_embeddings[0]], 
    [original_embeddings[1]]
)[0][0]

sim_reduced = cosine_similarity(
    [reduced_embeddings[0]], 
    [reduced_embeddings[1]]
)[0][0]

print(f"\nğŸ“Š Ø´Ø¨Ø§Ù‡Øª Ø§ØµÙ„ÛŒ: {sim_original:.4f}")
print(f"ğŸ“Š Ø´Ø¨Ø§Ù‡Øª Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡: {sim_reduced:.4f}")
print(f"ğŸ“Š Ø®Ø·Ø§: {abs(sim_original - sim_reduced):.4f}")
                </div>
            </div>
            
            <h3><span class="emoji">4ï¸âƒ£</span> Quantization - Ú©ÙˆØ§Ù†ØªÛŒØ²Ù‡â€ŒØ³Ø§Ø²ÛŒ</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> ØªØ¨Ø¯ÛŒÙ„ float64 Ø¨Ù‡ float16</h4>
                <div class="code">
# embeddings Ø§ØµÙ„ÛŒ (float64)
embeddings_f64 = np.array(embeddings, dtype=np.float64)

# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ float32
embeddings_f32 = embeddings_f64.astype(np.float32)

# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ float16
embeddings_f16 = embeddings_f64.astype(np.float16)

# Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø­Ø¬Ù…
size_f64 = embeddings_f64.nbytes / 1024
size_f32 = embeddings_f32.nbytes / 1024
size_f16 = embeddings_f16.nbytes / 1024

print("ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø­Ø¬Ù…:")
print(f"  float64: {size_f64:.2f} KB")
print(f"  float32: {size_f32:.2f} KB (Ú©Ø§Ù‡Ø´ {(1-size_f32/size_f64)*100:.0f}%)")
print(f"  float16: {size_f16:.2f} KB (Ú©Ø§Ù‡Ø´ {(1-size_f16/size_f64)*100:.0f}%)")

# ØªØ³Øª Ø¯Ù‚Øª
sim_f64 = cosine_similarity([embeddings_f64[0]], [embeddings_f64[1]])[0][0]
sim_f32 = cosine_similarity([embeddings_f32[0]], [embeddings_f32[1]])[0][0]
sim_f16 = cosine_similarity([embeddings_f16[0]], [embeddings_f16[1]])[0][0]

print(f"\nğŸ“Š Ø´Ø¨Ø§Ù‡Øª float64: {sim_f64:.6f}")
print(f"ğŸ“Š Ø´Ø¨Ø§Ù‡Øª float32: {sim_f32:.6f}")
print(f"ğŸ“Š Ø´Ø¨Ø§Ù‡Øª float16: {sim_f16:.6f}")
                </div>
            </div>
            
            <div class="key-point box">
                <h3><span class="emoji">ğŸ’¡</span> ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ</h3>
                <table>
                    <thead>
                        <tr>
                            <th>ØªÚ©Ù†ÛŒÚ©</th>
                            <th>Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù…</th>
                            <th>Ú©Ø§Ù‡Ø´ Ø¯Ù‚Øª</th>
                            <th>ØªÙˆØµÛŒÙ‡</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Caching</strong></td>
                            <td>-</td>
                            <td>0%</td>
                            <td>âœ… Ù‡Ù…ÛŒØ´Ù‡</td>
                        </tr>
                        <tr>
                            <td><strong>Batch Processing</strong></td>
                            <td>-</td>
                            <td>0%</td>
                            <td>âœ… Ù‡Ù…ÛŒØ´Ù‡</td>
                        </tr>
                        <tr>
                            <td><strong>PCA (256D)</strong></td>
                            <td>83%</td>
                            <td>~5%</td>
                            <td>âœ… ØªÙˆØµÛŒÙ‡</td>
                        </tr>
                        <tr>
                            <td><strong>Float32</strong></td>
                            <td>50%</td>
                            <td><1%</td>
                            <td>âœ… ØªÙˆØµÛŒÙ‡</td>
                        </tr>
                        <tr>
                            <td><strong>Float16</strong></td>
                            <td>75%</td>
                            <td>~3%</td>
                            <td>âš ï¸ Ø¨Ø§ Ø§Ø­ØªÛŒØ§Ø·</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 10: Ù¾Ø±ÙˆÚ˜Ù‡ Ø¹Ù…Ù„ÛŒ Ú©Ø§Ù…Ù„ -->
        <div class="slide">
            <div class="slide-number">10</div>
            <h2>ğŸ¯ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¹Ù…Ù„ÛŒ: Ø³ÛŒØ³ØªÙ… Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯</h2>
            
            <div class="highlight box">
                <h3><span class="emoji">ğŸš€</span> Ù‡Ø¯Ù Ù¾Ø±ÙˆÚ˜Ù‡</h3>
                <p style="font-size: 1.3em;">
                    Ø³Ø§Ø®Øª ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ú©Ø§Ù…Ù„ Ú©Ù‡ Ø¨ØªÙˆØ§Ù†Ø¯ Ø§Ø³Ù†Ø§Ø¯ Ø±Ø§ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ú©Ø±Ø¯Ù‡ØŒ 
                    Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†Ø¯ØŒ Ùˆ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡Ø¯.
                </p>
            </div>
            
            <div class="example box">
                <h3><span class="emoji">ğŸ’»</span> Ú©Ø¯ Ú©Ø§Ù…Ù„ Ù¾Ø±ÙˆÚ˜Ù‡</h3>
                <div class="code">
import numpy as np
import json
import pickle
from datetime import datetime
from typing import List, Dict
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI

class SmartSearchEngine:
    """Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Embeddings"""
    
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
        self.documents = []
        self.embeddings = []
        self.metadata = []
        self.model = "text-embedding-3-small"
    
    def add_document(self, text: str, metadata: Dict = None):
        """Ø§ÙØ²ÙˆØ¯Ù† ÛŒÚ© Ø³Ù†Ø¯"""
        # ØªÙˆÙ„ÛŒØ¯ embedding
        embedding = self._get_embedding(text)
        
        # Ø°Ø®ÛŒØ±Ù‡
        self.documents.append(text)
        self.embeddings.append(embedding)
        self.metadata.append(metadata or {})
        
        return len(self.documents) - 1
    
    def add_documents_batch(self, texts: List[str], 
                            metadata_list: List[Dict] = None):
        """Ø§ÙØ²ÙˆØ¯Ù† Ú†Ù†Ø¯ Ø³Ù†Ø¯ Ø¨Ù‡ ØµÙˆØ±Øª batch"""
        print(f"ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø§ÙØ²ÙˆØ¯Ù† {len(texts)} Ø³Ù†Ø¯...")
        
        # ØªÙˆÙ„ÛŒØ¯ embeddings Ø¨Ù‡ ØµÙˆØ±Øª batch
        response = self.client.embeddings.create(
            input=texts,
            model=self.model
        )
        
        embeddings = [item.embedding for item in response.data]
        
        # Ø°Ø®ÛŒØ±Ù‡
        self.documents.extend(texts)
        self.embeddings.extend(embeddings)
        
        if metadata_list:
            self.metadata.extend(metadata_list)
        else:
            self.metadata.extend([{}] * len(texts))
        
        print(f"âœ… {len(texts)} Ø³Ù†Ø¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯")
        print(f"ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹ Ø§Ø³Ù†Ø§Ø¯: {len(self.documents)}")
    
    def search(self, query: str, top_k: int = 5, 
               min_score: float = 0.0) -> List[Dict]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ"""
        if not self.documents:
            return []
        
        # ØªÙˆÙ„ÛŒØ¯ embedding Ø¨Ø±Ø§ÛŒ query
        query_embedding = self._get_embedding(query)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª
        similarities = cosine_similarity(
            [query_embedding],
            self.embeddings
        )[0]
        
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ min_score
        valid_indices = np.where(similarities >= min_score)[0]
        
        if len(valid_indices) == 0:
            return []
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
        sorted_indices = valid_indices[
            np.argsort(similarities[valid_indices])[::-1]
        ][:top_k]
        
        # Ø³Ø§Ø®Øª Ù†ØªØ§ÛŒØ¬
        results = []
        for idx in sorted_indices:
            results.append({
                'id': int(idx),
                'document': self.documents[idx],
                'score': float(similarities[idx]),
                'metadata': self.metadata[idx]
            })
        
        return results
    
    def save(self, filepath: str = "search_engine.pkl"):
        """Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬Ùˆ"""
        data = {
            'documents': self.documents,
            'embeddings': self.embeddings,
            'metadata': self.metadata,
            'model': self.model,
            'created_at': datetime.now().isoformat()
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(data, f)
        
        print(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filepath}")
        print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯: {len(self.documents)}")
    
    def load(self, filepath: str = "search_engine.pkl"):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬Ùˆ"""
        with open(filepath, 'rb') as f:
            data = pickle.load(f)
        
        self.documents = data['documents']
        self.embeddings = data['embeddings']
        self.metadata = data['metadata']
        self.model = data['model']
        
        print(f"âœ… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {filepath}")
        print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯: {len(self.documents)}")
        print(f"ğŸ“… ØªØ§Ø±ÛŒØ® Ø§ÛŒØ¬Ø§Ø¯: {data.get('created_at', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
    
    def get_stats(self) -> Dict:
        """Ø¢Ù…Ø§Ø± Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬Ùˆ"""
        if not self.embeddings:
            return {}
        
        embeddings_array = np.array(self.embeddings)
        
        return {
            'total_documents': len(self.documents),
            'embedding_dimensions': embeddings_array.shape[1],
            'total_size_mb': embeddings_array.nbytes / (1024 * 1024),
            'model': self.model
        }
    
    def _get_embedding(self, text: str) -> List[float]:
        """ØªÙˆÙ„ÛŒØ¯ embedding Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù…ØªÙ†"""
        response = self.client.embeddings.create(
            input=[text],
            model=self.model
        )
        return response.data[0].embedding


# ==================== Ø§Ø³ØªÙØ§Ø¯Ù‡ ====================

# 1. Ø§ÛŒØ¬Ø§Ø¯ Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬Ùˆ
engine = SmartSearchEngine(api_key="your-api-key")

# 2. Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø³Ù†Ø§Ø¯
documents = [
    "Python ÛŒÚ© Ø²Ø¨Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ø§Ø³Øª",
    "Django Ø¨Ù‡ØªØ±ÛŒÙ† ÙØ±ÛŒÙ…ÙˆØ±Ú© ÙˆØ¨ Ù¾Ø§ÛŒØªÙˆÙ† Ø§Ø³Øª",
    "Machine Learning Ø¨Ø§ Python Ø¢Ø³Ø§Ù† Ø§Ø³Øª",
    "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ Ø§Ø³Øª",
    "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ù…ÛŒÙ‚ Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø§Ø³Øª"
]

metadata_list = [
    {'category': 'programming', 'lang': 'python'},
    {'category': 'web', 'lang': 'python'},
    {'category': 'ai', 'lang': 'python'},
    {'category': 'ai', 'lang': 'general'},
    {'category': 'ai', 'lang': 'general'}
]

engine.add_documents_batch(documents, metadata_list)

# 3. Ø°Ø®ÛŒØ±Ù‡
engine.save()
# 4. Ø¬Ø³ØªØ¬Ùˆ
query = "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ"
results = engine.search(query, top_k=3, min_score=0.5)

print(f"\nğŸ” Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ: '{query}'\n")
for i, result in enumerate(results, 1):
    print(f"{i}. {result['document']}")
    print(f"   Ø§Ù…ØªÛŒØ§Ø²: {result['score']:.4f}")
    print(f"   Ø¯Ø³ØªÙ‡: {result['metadata'].get('category', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
    print()

# 5. Ø¢Ù…Ø§Ø±
stats = engine.get_stats()
print("ğŸ“Š Ø¢Ù…Ø§Ø± Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬Ùˆ:")
for key, value in stats.items():
    print(f"  {key}: {value}")
                </div>
            </div>
            
            <div class="success box">
                <h3><span class="emoji">âœ…</span> ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡</h3>
                <ul>
                    <li>âœ… Ø§ÙØ²ÙˆØ¯Ù† ØªÚ© Ø³Ù†Ø¯ ÛŒØ§ batch</li>
                    <li>âœ… Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ± Ø§Ù…ØªÛŒØ§Ø²</li>
                    <li>âœ… Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ</li>
                    <li>âœ… Metadata Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø³Ù†Ø¯</li>
                    <li>âœ… Ø¢Ù…Ø§Ø± Ùˆ Ú¯Ø²Ø§Ø±Ø´</li>
                    <li>âœ… Ú©Ø¯ ØªÙ…ÛŒØ² Ùˆ Ù‚Ø§Ø¨Ù„ ØªÙˆØ³Ø¹Ù‡</li>
                </ul>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 11: Ø®Ø·Ø§Ù‡Ø§ Ùˆ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ -->
        <div class="slide">
            <div class="slide-number">11</div>
            <h2>ğŸ› Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø±Ø§ÛŒØ¬ Ùˆ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§</h2>
            
            <h3><span class="emoji">1ï¸âƒ£</span> Ø®Ø·Ø§ÛŒ API Key</h3>
            
            <div class="danger box">
                <h4><span class="emoji">âŒ</span> Ø®Ø·Ø§</h4>
                <div class="code">
AuthenticationError: Incorrect API key provided
                </div>
                <h4><span class="emoji">âœ…</span> Ø±Ø§Ù‡â€ŒØ­Ù„</h4>
                <ul>
                    <li>API Key Ø±Ø§ Ø§Ø² platform.openai.com Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯</li>
                    <li>Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ ÙØ¶Ø§ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø¶Ø§ÙÛŒ Ù†Ø¯Ø§Ø±Ø¯</li>
                    <li>Ø§Ø² Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯</li>
                </ul>
                <div class="code">
import os
from openai import OpenAI

# Ø±ÙˆØ´ ØµØ­ÛŒØ­
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("API Key ÛŒØ§ÙØª Ù†Ø´Ø¯")

client = OpenAI(api_key=api_key)
                </div>
            </div>
            
            <h3><span class="emoji">2ï¸âƒ£</span> Ø®Ø·Ø§ÛŒ Rate Limit</h3>
            
            <div class="danger box">
                <h4><span class="emoji">âŒ</span> Ø®Ø·Ø§</h4>
                <div class="code">
RateLimitError: Rate limit exceeded
                </div>
                <h4><span class="emoji">âœ…</span> Ø±Ø§Ù‡â€ŒØ­Ù„: Retry Ø¨Ø§ Backoff</h4>
                <div class="code">
import time
from openai import OpenAI, RateLimitError

def get_embedding_with_retry(text, max_retries=3):
    """ØªÙˆÙ„ÛŒØ¯ embedding Ø¨Ø§ retry"""
    client = OpenAI()
    
    for attempt in range(max_retries):
        try:
            response = client.embeddings.create(
                input=[text],
                model="text-embedding-3-small"
            )
            return response.data[0].embedding
        
        except RateLimitError as e:
            if attempt == max_retries - 1:
                raise
            
            wait_time = 2 ** attempt  # exponential backoff
            print(f"âš ï¸ Rate limit. ØµØ¨Ø± {wait_time}s...")
            time.sleep(wait_time)
        
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§: {e}")
            raise

# Ø§Ø³ØªÙØ§Ø¯Ù‡
embedding = get_embedding_with_retry("Ù…ØªÙ† ØªØ³Øª")
                </div>
            </div>
            
            <h3><span class="emoji">3ï¸âƒ£</span> Ø®Ø·Ø§ÛŒ Ø­Ø§ÙØ¸Ù‡</h3>
            
            <div class="danger box">
                <h4><span class="emoji">âŒ</span> Ø®Ø·Ø§</h4>
                <div class="code">
MemoryError: Unable to allocate array
                </div>
                <h4><span class="emoji">âœ…</span> Ø±Ø§Ù‡â€ŒØ­Ù„: Ù¾Ø±Ø¯Ø§Ø²Ø´ Chunk</h4>
                <div class="code">
def process_large_dataset(documents, chunk_size=100):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø²Ø±Ú¯ Ø¨Ù‡ ØµÙˆØ±Øª chunk"""
    all_embeddings = []
    
    for i in range(0, len(documents), chunk_size):
        chunk = documents[i:i + chunk_size]
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ chunk
        embeddings = get_embeddings_batch(chunk)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØ³Ú© (Ù†Ù‡ RAM)
        np.save(f'embeddings_chunk_{i}.npy', embeddings)
        
        print(f"âœ… Chunk {i//chunk_size + 1} Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯")
    
    return "âœ… ØªÙ…Ø§Ù… chunks Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù†Ø¯"

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ø¹Ø¯Ø§Ù‹
def load_embeddings_lazy(chunk_id):
    return np.load(f'embeddings_chunk_{chunk_id}.npy')
                </div>
            </div>
            
            <h3><span class="emoji">4ï¸âƒ£</span> Ø®Ø·Ø§ÛŒ Ø´Ø¨Ø§Ù‡Øª ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡</h3>
            
            <div class="warning box">
                <h4><span class="emoji">âš ï¸</span> Ù…Ø´Ú©Ù„: Ø´Ø¨Ø§Ù‡Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¬ÛŒØ¨</h4>
                <p>Ú¯Ø§Ù‡ÛŒ Ú©Ù„Ù…Ø§Øª Ù†Ø§Ù…Ø±ØªØ¨Ø· Ø´Ø¨Ø§Ù‡Øª Ø¨Ø§Ù„Ø§ Ø¯Ø§Ø±Ù†Ø¯</p>
                
                <h4><span class="emoji">âœ…</span> Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:</h4>
                <div class="code">
# 1. Normalize Ú©Ø±Ø¯Ù† embeddings
from sklearn.preprocessing import normalize

embeddings_normalized = normalize(embeddings, norm='l2')

# 2. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² threshold
min_similarity = 0.7
results = [r for r in results if r['score'] >= min_similarity]

# 3. Re-ranking Ø¨Ø§ Ù…Ø¯Ù„ Ø¯ÛŒÚ¯Ø±
from sentence_transformers import CrossEncoder

reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
scores = reranker.predict([(query, doc) for doc in candidates])
                </div>
            </div>
            
            <h3><span class="emoji">5ï¸âƒ£</span> Ø®Ø·Ø§ÛŒ UTF-8</h3>
            
            <div class="danger box">
                <h4><span class="emoji">âŒ</span> Ø®Ø·Ø§</h4>
                <div class="code">
UnicodeDecodeError: 'utf-8' codec can't decode
                </div>
                <h4><span class="emoji">âœ…</span> Ø±Ø§Ù‡â€ŒØ­Ù„</h4>
                <div class="code">
# Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø¨Ø§ encoding ØµØ­ÛŒØ­
with open('data.txt', 'r', encoding='utf-8') as f:
    text = f.read()

# ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² errors='ignore'
with open('data.txt', 'r', encoding='utf-8', errors='ignore') as f:
    text = f.read()

# Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†
import unicodedata

def clean_text(text):
    # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ú©Ù†ØªØ±Ù„ÛŒ
    text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C')
    return text.strip()
                </div>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 12: Best Practices -->
        <div class="slide">
            <div class="slide-number">12</div>
            <h2>â­ Best Practices - Ø¨Ù‡ØªØ±ÛŒÙ† Ø´ÛŒÙˆÙ‡â€ŒÙ‡Ø§</h2>
            
            <h3><span class="emoji">1ï¸âƒ£</span> Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ†</h3>
            
            <div class="info box">
                <h4>Ú†Ø±Ø§ Ù…Ù‡Ù… Ø§Ø³ØªØŸ</h4>
                <p>Ù…ØªÙ† ØªÙ…ÛŒØ² â†’ Embedding Ø¨Ù‡ØªØ± â†’ Ù†ØªØ§ÛŒØ¬ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±</p>
            </div>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> ØªØ§Ø¨Ø¹ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„</h4>
                <div class="code">
import re
from hazm import Normalizer, word_tokenize

normalizer = Normalizer()

def preprocess_text(text):
    """Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ"""
    
    # 1. Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
    text = normalizer.normalize(text)
    
    # 2. Ø­Ø°Ù URL
    text = re.sub(r'http\S+', '', text)
    
    # 3. Ø­Ø°Ù Ø§ÛŒÙ…ÛŒÙ„
    text = re.sub(r'\S+@\S+', '', text)
    
    # 4. Ø­Ø°Ù Ø§Ø¹Ø¯Ø§Ø¯ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
    # text = re.sub(r'\d+', '', text)
    
    # 5. Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø®Ø§Øµ
    text = re.sub(r'[^\w\s]', ' ', text)
    
    # 6. Ø­Ø°Ù ÙØ¶Ø§ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø¶Ø§ÙÛŒ
    text = ' '.join(text.split())
    
    # 7. ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ lowercase (Ø¨Ø±Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)
    # text = text.lower()
    
    return text.strip()

# Ù…Ø«Ø§Ù„
raw_text = "  Ø§ÛŒÙ†   ÛŒÚ© Ù…ØªÙ†    ØªØ³Øª Ø§Ø³Øª!!! https://example.com  "
clean_text = preprocess_text(raw_text)
print(f"Ù‚Ø¨Ù„: '{raw_text}'")
print(f"Ø¨Ø¹Ø¯: '{clean_text}'")
                </div>
            </div>
            
            <h3><span class="emoji">2ï¸âƒ£</span> Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Chunking</h3>
            
            <div class="warning box">
                <h4>Ú†Ø±Ø§ ChunkingØŸ</h4>
                <p>Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø·ÙˆÙ„ Ø¯Ø§Ø±Ù†Ø¯. Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø¨Ù„Ù†Ø¯ Ø¨Ø§ÛŒØ¯ ØªÙ‚Ø³ÛŒÙ… Ø´ÙˆÙ†Ø¯.</p>
            </div>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> ØªÙ‚Ø³ÛŒÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…ØªÙ†</h4>
                <div class="code">
def smart_chunk_text(text, chunk_size=500, overlap=50):
    """ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø¨Ø§ Ø­ÙØ¸ Ø¬Ù…Ù„Ø§Øª Ú©Ø§Ù…Ù„"""
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ø¬Ù…Ù„Ø§Øª
    sentences = re.split(r'[.!?]\s+', text)
    
    chunks = []
    current_chunk = []
    current_length = 0
    
    for sentence in sentences:
        sentence_length = len(sentence.split())
        
        if current_length + sentence_length > chunk_size:
            # Ø°Ø®ÛŒØ±Ù‡ chunk ÙØ¹Ù„ÛŒ
            if current_chunk:
                chunks.append(' '.join(current_chunk))
            
            # Ø´Ø±ÙˆØ¹ chunk Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ overlap
            overlap_sentences = current_chunk[-2:] if len(current_chunk) > 2 else []
            current_chunk = overlap_sentences + [sentence]
            current_length = sum(len(s.split()) for s in current_chunk)
        else:
            current_chunk.append(sentence)
            current_length += sentence_length
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† chunk Ø¢Ø®Ø±
    if current_chunk:
        chunks.append(' '.join(current_chunk))
    
    return chunks

# Ù…Ø«Ø§Ù„
long_text = """
Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† Ø¨Ù„Ù†Ø¯ Ø§Ø³Øª. Ø¬Ù…Ù„Ù‡ Ø§ÙˆÙ„.
Ø¬Ù…Ù„Ù‡ Ø¯ÙˆÙ… Ø§ÛŒÙ†Ø¬Ø§Ø³Øª. Ø¬Ù…Ù„Ù‡ Ø³ÙˆÙ….
Ùˆ Ø¬Ù…Ù„Ù‡ Ú†Ù‡Ø§Ø±Ù…. Ù¾Ù†Ø¬Ù… Ùˆ Ø´Ø´Ù….
""" * 10

chunks = smart_chunk_text(long_text, chunk_size=50)
print(f"ØªØ¹Ø¯Ø§Ø¯ chunks: {len(chunks)}")
for i, chunk in enumerate(chunks[:3], 1):
    print(f"\nChunk {i}: {chunk[:100]}...")
                </div>
            </div>
            
            <h3><span class="emoji">3ï¸âƒ£</span> Monitoring Ùˆ Logging</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> Ø³ÛŒØ³ØªÙ… Ù„Ø§Ú¯ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ</h4>
                <div class="code">
import logging
from datetime import datetime

# ØªÙ†Ø¸ÛŒÙ… logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('embeddings.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class MonitoredEmbedding:
    def __init__(self):
        self.stats = {
            'total_requests': 0,
            'total_tokens': 0,
            'errors': 0
        }
    
    def get_embedding(self, text):
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸ”„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª embedding Ø¨Ø±Ø§ÛŒ {len(text)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
            
            response = client.embeddings.create(
                input=[text],
                model="text-embedding-3-small"
            )
            
            embedding = response.data[0].embedding
            
            # Ø¢Ù…Ø§Ø±
            self.stats['total_requests'] += 1
            self.stats['total_tokens'] += response.usage.total_tokens
            
            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… Ù…ÙˆÙÙ‚ Ø¯Ø± {duration:.2f}s")
            
            return embedding
        
        except Exception as e:
            self.stats['errors'] += 1
            logger.error(f"âŒ Ø®Ø·Ø§: {e}")
            raise
    
    def get_stats(self):
        logger.info(f"ğŸ“Š Ø¢Ù…Ø§Ø±: {self.stats}")
        return self.stats
                </div>
            </div>
            
            <h3><span class="emoji">4ï¸âƒ£</span> Testing Ùˆ Validation</h3>
            
            <div class="example box">
                <h4><span class="emoji">ğŸ’»</span> ØªØ³Øª Ú©ÛŒÙÛŒØª Embeddings</h4>
                <div class="code">
def test_embedding_quality():
    """ØªØ³Øª Ú©ÛŒÙÛŒØª embeddings"""
    
    # ØªØ³Øª 1: Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø§ÛŒØ¯ Ù†Ø²Ø¯ÛŒÚ© Ø¨Ø§Ø´Ù†Ø¯
    similar_pairs = [
        ("Ø³Ú¯", "Ú¯Ø±Ø¨Ù‡"),
        ("Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ", "Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ"),
        ("Ø®ÙˆØ´Ø­Ø§Ù„", "Ø´Ø§Ø¯")
    ]
    
    print("ğŸ§ª ØªØ³Øª 1: Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡")
    for word1, word2 in similar_pairs:
        emb1 = get_embedding(word1)
        emb2 = get_embedding(word2)
        sim = cosine_similarity([emb1], [emb2])[0][0]
        
        status = "âœ…" if sim > 0.6 else "âŒ"
        print(f"  {status} '{word1}' â†” '{word2}': {sim:.4f}")
    
    # ØªØ³Øª 2: Ú©Ù„Ù…Ø§Øª Ù†Ø§Ù…Ø±ØªØ¨Ø· Ø¨Ø§ÛŒØ¯ Ø¯ÙˆØ± Ø¨Ø§Ø´Ù†Ø¯
    dissimilar_pairs = [
        ("Ø³Ú¯", "Ù…Ø§Ø´ÛŒÙ†"),
        ("Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ", "ØºØ°Ø§"),
        ("Ø®ÙˆØ´Ø­Ø§Ù„", "Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±")
    ]
    
    print("\nğŸ§ª ØªØ³Øª 2: Ú©Ù„Ù…Ø§Øª Ù†Ø§Ù…Ø±ØªØ¨Ø·")
    for word1, word2 in dissimilar_pairs:
        emb1 = get_embedding(word1)
        emb2 = get_embedding(word2)
        sim = cosine_similarity([emb1], [emb2])[0][0]
        
        status = "âœ…" if sim < 0.5 else "âŒ"
        print(f"  {status} '{word1}' â†” '{word2}': {sim:.4f}")
    
    # ØªØ³Øª 3: Ø«Ø¨Ø§Øª (Ù‡Ù…Ø§Ù† ÙˆØ±ÙˆØ¯ÛŒ â†’ Ù‡Ù…Ø§Ù† Ø®Ø±ÙˆØ¬ÛŒ)
    print("\nğŸ§ª ØªØ³Øª 3: Ø«Ø¨Ø§Øª")
    text = "Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† ØªØ³Øª Ø§Ø³Øª"
    emb1 = get_embedding(text)
    emb2 = get_embedding(text)
    sim = cosine_similarity([emb1], [emb2])[0][0]
    
    status = "âœ…" if sim > 0.99 else "âŒ"
    print(f"  {status} Ø«Ø¨Ø§Øª: {sim:.6f}")

# Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª
test_embedding_quality()
                </div>
            </div>
            
            <div class="key-point box">
                <h3><span class="emoji">ğŸ“‹</span> Checklist Ù‚Ø¨Ù„ Ø§Ø² Production</h3>
                <ul style="font-size: 1.1em;">
                    <li>â˜‘ï¸ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡</li>
                    <li>â˜‘ï¸ Caching ÙØ¹Ø§Ù„ Ø§Ø³Øª</li>
                    <li>â˜‘ï¸ Error handling Ú©Ø§Ù…Ù„</li>
                    <li>â˜‘ï¸ Logging Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯Ù‡</li>
                    <li>â˜‘ï¸ Rate limiting Ø±Ø¹Ø§ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆØ¯</li>
                    <li>â˜‘ï¸ ØªØ³Øªâ€ŒÙ‡Ø§ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ùˆ Ù¾Ø§Ø³ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯</li>
                    <li>â˜‘ï¸ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„ Ø§Ø³Øª</li>
                    <li>â˜‘ï¸ Monitoring Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª</li>
                </ul>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 13: Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ø§Ø¯Ø§Ù…Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ -->
        <div class="slide">
            <div class="slide-number">13</div>
            <h2>ğŸ“š Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ø§Ø¯Ø§Ù…Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ</h2>
            
            <h3><span class="emoji">ğŸ“–</span> Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø³Ù…ÛŒ</h3>
            
            <div class="grid">
                <div class="card">
                    <h4><span class="emoji">ğŸ¤–</span> OpenAI</h4>
                    <ul>
                        <li><a href="https://platform.openai.com/docs/guides/embeddings" target="_blank">Embeddings Guide</a></li>
                        <li><a href="https://platform.openai.com/docs/api-reference/embeddings" target="_blank">API Reference</a></li>
                        <li><a href="https://cookbook.openai.com" target="_blank">Cookbook</a></li>
                    </ul>
                </div>
                
                <div class="card">
                    <h4><span class="emoji">ğŸ¤—</span> Hugging Face</h4>
                    <ul>
                        <li>Sentence Transformers</li>
                        <li>Pre-trained Models</li>
                        <li>Datasets</li>
                    </ul>
                </div>
                
                <div class="card">
                    <h4><span class="emoji">ğŸ“Š</span> Vector Databases</h4>
                    <ul>
                        <li>Pinecone Docs</li>
                        <li>Weaviate Docs</li>
                        <li>ChromaDB Docs</li>
                    </ul>
                </div>
                
                <div class="card">
                    <h4><span class="emoji">ğŸ“˜</span> Papers</h4>
                    <ul>
                        <li>Word2Vec (2013)</li>
                        <li>GloVe (2014)</li>
                        <li>BERT (2018)</li>
                        <li>Sentence-BERT (2019)</li>
                    </ul>
                </div>
            </div>
            
            <h3><span class="emoji">ğŸ“</span> Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§</h3>
            
            <table>
                <thead>
                    <tr>
                        <th>Ø¯ÙˆØ±Ù‡</th>
                        <th>Ø³Ø·Ø­</th>
                        <th>Ù…Ø¯Øª</th>
                        <th>ØªÙˆØµÛŒÙ‡</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>DeepLearning.AI - NLP</strong></td>
                        <td>Ù…Ø¨ØªØ¯ÛŒ</td>
                        <td>4 Ù‡ÙØªÙ‡</td>
                        <td>â­â­â­â­â­</td>
                    </tr>
                    <tr>
                        <td><strong>Fast.ai - NLP</strong></td>
                        <td>Ù…ØªÙˆØ³Ø·</td>
                        <td>8 Ù‡ÙØªÙ‡</td>
                        <td>â­â­â­â­â­</td>
                    </tr>
                    <tr>
                        <td><strong>Stanford CS224N</strong></td>
                        <td>Ù¾ÛŒØ´Ø±ÙØªÙ‡</td>
                        <td>12 Ù‡ÙØªÙ‡</td>
                        <td>â­â­â­â­â­</td>
                    </tr>
                    <tr>
                        <td><strong>Hugging Face Course</strong></td>
                        <td>Ù‡Ù…Ù‡ Ø³Ø·ÙˆØ­</td>
                        <td>Ø±Ø§ÛŒÚ¯Ø§Ù†</td>
                        <td>â­â­â­â­</td>
                    </tr>
                </tbody>
            </table>
            
            <h3><span class="emoji">ğŸ’»</span> Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯</h3>
            
            <div class="grid">
                <div class="card">
                    <h4>OpenAI</h4>
                    <div class="code" style="font-size: 0.9em;">
pip install openai
                    </div>
                </div>
                
                <div class="card">
                    <h4>Sentence Transformers</h4>
                    <div class="code" style="font-size: 0.9em;">
pip install sentence-transformers
                    </div>
                </div>
                
                <div class="card">
                    <h4>Gensim</h4>
                    <div class="code" style="font-size: 0.9em;">
pip install gensim
                    </div>
                </div>
                
                <div class="card">
                    <h4>Hazm (ÙØ§Ø±Ø³ÛŒ)</h4>
                    <div class="code" style="font-size: 0.9em;">
pip install hazm
                    </div>
                </div>
                
                <div class="card">
                    <h4>FAISS</h4>
                    <div class="code" style="font-size: 0.9em;">
pip install faiss-cpu
                    </div>
                </div>
                
                <div class="card">
                    <h4>ChromaDB</h4>
                    <div class="code" style="font-size: 0.9em;">
pip install chromadb
                    </div>
                </div>
            </div>
            
            <h3><span class="emoji">ğŸš€</span> Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ</h3>
            
            <div class="grid">
                <div class="card">
                    <h4>1ï¸âƒ£ Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬ÙˆÛŒ Ø´Ø®ØµÛŒ</h4>
                    <p>Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø´Ø®ØµÛŒ (PDF, Word, TXT)</p>
                    <p><strong>Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§:</strong> Document Loading, Chunking, Search</p>
                </div>
                
                <div class="card">
                    <h4>2ï¸âƒ£ Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡ Ù…Ø­ØµÙˆÙ„</h4>
                    <p>ØªÙˆØµÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªÙˆØ¶ÛŒØ­Ø§Øª Ùˆ Ù†Ø¸Ø±Ø§Øª</p>
                    <p><strong>Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§:</strong> Similarity, Ranking, Filtering</p>
                </div>
                
                <div class="card">
                    <h4>3ï¸âƒ£ ØªØ´Ø®ÛŒØµ ØªÙ‚Ù„Ø¨ Ù…ØªÙ†</h4>
                    <p>Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…ØªÙˆÙ† Ù…Ø´Ø§Ø¨Ù‡ (Plagiarism)</p>
                    <p><strong>Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§:</strong> Similarity Threshold, Chunking</p>
                </div>
                
                <div class="card">
                    <h4>4ï¸âƒ£ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®Ø¨Ø±</h4>
                    <p>Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø®Ø¨Ø§Ø±</p>
                    <p><strong>Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§:</strong> Classification, Clustering</p>
                </div>
                
                <div class="card">
                    <h4>5ï¸âƒ£ Ú†Øªâ€ŒØ¨Ø§Øª Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡</h4>
                    <p>Ú†Øªâ€ŒØ¨Ø§Øª Ú©Ù‡ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø¯Ø§Ø±Ø¯</p>
                    <p><strong>Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§:</strong> Context Management, RAG</p>
                </div>
                
                <div class="card">
                    <h4>6ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª</h4>
                    <p>ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³ Ù…Ø«Ø¨Øª/Ù…Ù†ÙÛŒ</p>
                    <p><strong>Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§:</strong> Classification, Fine-tuning</p>
                </div>
            </div>
            
            <div class="highlight box">
                <h3><span class="emoji">ğŸ¯</span> Ù…Ø³ÛŒØ± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ</h3>
                <ol style="font-size: 1.2em; line-height: 2.5;">
                    <li><strong>Ù‡ÙØªÙ‡ 1-2:</strong> Ù…ÙØ§Ù‡ÛŒÙ… Ù¾Ø§ÛŒÙ‡ Ùˆ Word2Vec</li>
                    <li><strong>Ù‡ÙØªÙ‡ 3-4:</strong> OpenAI Embeddings Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª</li>
                    <li><strong>Ù‡ÙØªÙ‡ 5-6:</strong> Ù¾Ø±ÙˆÚ˜Ù‡ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ</li>
                    <li><strong>Ù‡ÙØªÙ‡ 7-8:</strong> Vector Databases Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ</li>
                    <li><strong>Ù‡ÙØªÙ‡ 9-10:</strong> Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ Production</li>
                </ol>
            </div>
            
            <div class="key-point box">
                <h3><span class="emoji">ğŸ’¡</span> Ù†Ú©Ø§Øª Ø·Ù„Ø§ÛŒÛŒ</h3>
                <ul style="font-size: 1.2em;">
                    <li>ğŸ¯ Ø¨Ø§ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯</li>
                    <li>ğŸ“š Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø§ Ø­ØªÙ…Ø§Ù‹ Ø¨Ø®ÙˆØ§Ù†ÛŒØ¯</li>
                    <li>ğŸ’» Ú©Ø¯Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±Ø§Ù† Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯</li>
                    <li>ğŸ¤ Ø¨Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¨Ù¾ÛŒÙˆÙ†Ø¯ÛŒØ¯ Ùˆ Ø³ÙˆØ§Ù„ Ø¨Ù¾Ø±Ø³ÛŒØ¯</li>
                    <li>ğŸ”„ Ù…Ø±ØªØ¨ ØªÙ…Ø±ÛŒÙ† Ú©Ù†ÛŒØ¯</li>
                    <li>ğŸ“Š Ù†ØªØ§ÛŒØ¬ Ø±Ø§ measure Ú©Ù†ÛŒØ¯</li>
                    <li>ğŸš€ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯</li>
                </ul>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 14: Ø®Ù„Ø§ØµÙ‡ Ùˆ Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ -->
        <div class="slide">
            <div class="slide-number">14</div>
            <h2>ğŸ“ Ø®Ù„Ø§ØµÙ‡ Ùˆ Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ</h2>
            
            <div class="architecture-diagram">
                <h3 style="color: #667eea; margin-bottom: 30px;">Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„ Embeddings</h3>
                
                <div class="component-box" style="background: #e3f2fd;">
                    <strong>1. Ù…ØªÙ† Ø®Ø§Ù…</strong><br>
                    "Ù…Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø±Ø§ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…"
                </div>
                <div class="arrow">â¬‡ï¸</div>
                
                <div class="component-box" style="background: #f3e5f5;">
                    <strong>2. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´</strong><br>
                    Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒØŒ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ
                </div>
                <div class="arrow">â¬‡ï¸</div>
                
                <div class="component-box" style="background: #fff3e0;">
                    <strong>3. ØªÙˆÙ„ÛŒØ¯ Embedding</strong><br>
                    OpenAI / Word2Vec / BERT
                </div>
                <div class="arrow">â¬‡ï¸</div>
                
                <div class="component-box" style="background: #e8f5e9;">
                    <strong>4. Ø¨Ø±Ø¯Ø§Ø± Ø¹Ø¯Ø¯ÛŒ</strong><br>
                    [0.23, -0.45, 0.67, ...]
                </div>
                <div class="arrow">â¬‡ï¸</div>
                
                <div class="component-box" style="background: #fce4ec;">
                    <strong>5. Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ</strong><br>
                    Vector Database / File
                </div>
                <div class="arrow">â¬‡ï¸</div>
                
                <div class="component-box" style="background: #e0f2f1;">
                    <strong>6. Ø¬Ø³ØªØ¬Ùˆ / Ù…Ù‚Ø§ÛŒØ³Ù‡</strong><br>
                    Cosine Similarity
                </div>
                <div class="arrow">â¬‡ï¸</div>
                
                <div class="component-box" style="background: #fff9c4;">
                    <strong>7. Ù†ØªØ§ÛŒØ¬</strong><br>
                    Ø§Ø³Ù†Ø§Ø¯ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø²
                </div>
            </div>
            
            <h3><span class="emoji">ğŸ“Š</span> Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù</h3>
            
            <table>
                <thead>
                    <tr>
                        <th>Ø±ÙˆØ´</th>
                        <th>Ø³Ø±Ø¹Øª</th>
                        <th>Ø¯Ù‚Øª</th>
                        <th>Ù‡Ø²ÛŒÙ†Ù‡</th>
                        <th>Ú©Ø§Ø±Ø¨Ø±Ø¯</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>One-Hot</strong></td>
                        <td>âš¡âš¡âš¡</td>
                        <td>â­</td>
                        <td>Ø±Ø§ÛŒÚ¯Ø§Ù†</td>
                        <td>Ø³Ø§Ø¯Ù‡ØŒ Ù‚Ø¯ÛŒÙ…ÛŒ</td>
                    </tr>
                    <tr>
                        <td><strong>Word2Vec</strong></td>
                        <td>âš¡âš¡âš¡</td>
                        <td>â­â­â­</td>
                        <td>Ø±Ø§ÛŒÚ¯Ø§Ù†</td>
                        <td>Ú©Ù„Ù…Ø§ØªØŒ Ø³Ø±ÛŒØ¹</td>
                    </tr>
                    <tr>
                        <td><strong>GloVe</strong></td>
                        <td>âš¡âš¡</td>
                        <td>â­â­â­</td>
                        <td>Ø±Ø§ÛŒÚ¯Ø§Ù†</td>
                        <td>Ú©Ù„Ù…Ø§ØªØŒ Ø¢Ù…Ø§Ø±ÛŒ</td>
                    </tr>
                    <tr>
                        <td><strong>BERT</strong></td>
                        <td>âš¡</td>
                        <td>â­â­â­â­</td>
                        <td>Ù…ØªÙˆØ³Ø·</td>
                        <td>Context-aware</td>
                    </tr>
                    <tr>
                        <td><strong>OpenAI</strong></td>
                        <td>âš¡âš¡</td>
                        <td>â­â­â­â­â­</td>
                        <td>Ù¾ÙˆÙ„ÛŒ</td>
                        <td>Production</td>
                    </tr>
                </tbody>
            </table>
            
            <h3><span class="emoji">âœ…</span> Ú†ÛŒØ²Ù‡Ø§ÛŒÛŒ Ú©Ù‡ ÛŒØ§Ø¯ Ú¯Ø±ÙØªÛŒÙ…</h3>
            
            <div class="grid">
                <div class="success box">
                    <h4>Ù…ÙØ§Ù‡ÛŒÙ… Ù¾Ø§ÛŒÙ‡</h4>
                    <ul>
                        <li>âœ… Embedding Ú†ÛŒØ³Øª</li>
                        <li>âœ… Ú†Ø±Ø§ Ù…Ù‡Ù… Ø§Ø³Øª</li>
                        <li>âœ… Ø§Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„Ù</li>
                        <li>âœ… ØªØ§Ø±ÛŒØ®Ú†Ù‡ ØªÚ©Ø§Ù…Ù„</li>
                    </ul>
                </div>
                
                <div class="success box">
                    <h4>Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ</h4>
                    <ul>
                        <li>âœ… Word2Vec</li>
                        <li>âœ… OpenAI API</li>
                        <li>âœ… Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª</li>
                        <li>âœ… Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ</li>
                    </ul>
                </div>
                
                <div class="success box">
                    <h4>Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§</h4>
                    <ul>
                        <li>âœ… Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ</li>
                        <li>âœ… Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡</li>
                        <li>âœ… Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ</li>
                        <li>âœ… Clustering</li>
                    </ul>
                </div>
                
                <div class="success box">
                    <h4>Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ</h4>
                    <ul>
                        <li>âœ… Caching</li>
                        <li>âœ… Batch Processing</li>
                        <li>âœ… Ú©Ø§Ù‡Ø´ Ø§Ø¨Ø¹Ø§Ø¯</li>
                        <li>âœ… Error Handling</li>
                    </ul>
                </div>
            </div>
            
            <div class="highlight box" style="margin-top: 40px;">
                <h3 style="text-align: center;"><span class="emoji">ğŸ¯</span> Ù‚Ø¯Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ</h3>
                <ol style="font-size: 1.3em; line-height: 2.5;">
                    <li><strong>ÛŒÚ© Ù¾Ø±ÙˆÚ˜Ù‡ Ú©ÙˆÚ†Ú© Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯</strong> (Ù…Ø«Ù„Ø§Ù‹ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ÛŒØ§Ø¯Ø¯Ø§Ø´Øªâ€ŒÙ‡Ø§)</li>
                    <li><strong>Ú©Ø¯Ù‡Ø§ÛŒ Ø§ÛŒÙ† Ø¢Ù…ÙˆØ²Ø´ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯</strong> Ùˆ Ø¨Ø§ Ø¢Ù†â€ŒÙ‡Ø§ Ø¢Ø²Ù…Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯</li>
                    <li><strong>Ø¨Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¨Ù¾ÛŒÙˆÙ†Ø¯ÛŒØ¯</strong> Ùˆ Ø³ÙˆØ§Ù„Ø§Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯</li>
                    <li><strong>Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±Ø§Ù† Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯</strong> Ø¯Ø± GitHub</li>
                    <li><strong>Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø§ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ú©Ù†ÛŒØ¯</strong> Ùˆ Ø¹Ù…ÛŒÙ‚â€ŒØªØ± Ø´ÙˆÛŒØ¯</li>
                </ol>
            </div>
            
            <div class="key-point box" style="margin-top: 40px;">
                <h3 style="text-align: center;"><span class="emoji">ğŸ’¡</span> Ù¾ÛŒØ§Ù… Ù†Ù‡Ø§ÛŒÛŒ</h3>
                <p style="font-size: 1.4em; text-align: center; line-height: 2.2;">
                    Embeddings Ù¾Ø§ÛŒÙ‡ Ùˆ Ø§Ø³Ø§Ø³ ØªÙ…Ø§Ù… Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ø±Ù† NLP Ùˆ AI Ù‡Ø³ØªÙ†Ø¯. 
                    Ø¨Ø§ ØªØ³Ù„Ø· Ø¨Ø± Ø§ÛŒÙ† Ù…ÙÙ‡ÙˆÙ…ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ùˆ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø³Ø§Ø²ÛŒØ¯.
                    <br><br>
                    <strong style="color: #667eea;">ÛŒØ§Ø¯ØªØ§Ù† Ø¨Ø§Ø´Ø¯: Ø¨Ù‡ØªØ±ÛŒÙ† Ø±Ø§Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒØŒ ØªÙ…Ø±ÛŒÙ† Ùˆ Ø³Ø§Ø®ØªÙ† Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³Øª! ğŸš€</strong>
                </p>
            </div>
        </div>

        <!-- Ø§Ø³Ù„Ø§ÛŒØ¯ 15: ØµÙØ­Ù‡ Ù¾Ø§ÛŒØ§Ù†ÛŒ -->
        <div class="slide">
            <div class="slide-number">15</div>
            <h1 style="text-align: center; color: #667eea; margin-top: 100px;">
                <span class="emoji">ğŸ‰</span>
                <br>
                ØªØ¨Ø±ÛŒÚ©!
                <br>
                <span style="font-size: 0.6em; color: #764ba2;">Ø´Ù…Ø§ Ø¢Ù…ÙˆØ²Ø´ Embeddings Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ø±Ø¯ÛŒØ¯</span>
            </h1>
            
            <div class="highlight box" style="margin-top: 80px;">
                <h2 style="text-align: center; border: none; color: #667eea;">
                    <span class="emoji">ğŸ†</span> Ú¯ÙˆØ§Ù‡ÛŒÙ†Ø§Ù…Ù‡ Ø¯Ø§Ù†Ø´
                </h2>
                <div style="text-align: center; font-size: 1.3em; line-height: 2.5; margin-top: 40px;">
                    <p><strong>Ø´Ù…Ø§ Ø§Ú©Ù†ÙˆÙ† Ù…ÛŒâ€ŒØ¯Ø§Ù†ÛŒØ¯:</strong></p>
                    <ul style="list-style: none; padding: 0;">
                        <li>âœ… Embedding Ú†ÛŒØ³Øª Ùˆ Ú†Ú¯ÙˆÙ†Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯</li>
                        <li>âœ… Ø§Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„Ù Embeddings</li>
                        <li>âœ… Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Word2Vec Ùˆ OpenAI</li>
                        <li>âœ… Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ù…Ø¹Ù†Ø§ÛŒÛŒ</li>
                        <li>âœ… Ø³Ø§Ø®Øª Ø³ÛŒØ³ØªÙ… Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯</li>
                        <li>âœ… Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Best Practices</li>
                        <li>âœ… Ø±ÙØ¹ Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ÛŒØ¬</li>
                    </ul>
                </div>
            </div>
            
            <div class="grid" style="margin-top: 60px;">
                <div class="card" style="text-align: center;">
                    <h3 style="color: #667eea;">ğŸ“Š Ø¢Ù…Ø§Ø± Ø´Ù…Ø§</h3>
                    <p style="font-size: 2em; font-weight: 700; color: #764ba2;">15</p>
                    <p>Ø§Ø³Ù„Ø§ÛŒØ¯ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ø´Ø¯Ù‡</p>
                </div>
                
                <div class="card" style="text-align: center;">
                    <h3 style="color: #667eea;">ğŸ’» Ú©Ø¯Ù‡Ø§</h3>
                    <p style="font-size: 2em; font-weight: 700; color: #764ba2;">40+</p>
                    <p>Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÛŒ</p>
                </div>
                
                <div class="card" style="text-align: center;">
                    <h3 style="color: #667eea;">ğŸ¯ Ù¾Ø±ÙˆÚ˜Ù‡</h3>
                    <p style="font-size: 2em; font-weight: 700; color: #764ba2;">1</p>
                    <p>Ù¾Ø±ÙˆÚ˜Ù‡ Ú©Ø§Ù…Ù„</p>
                </div>
                
                <div class="card" style="text-align: center;">
                    <h3 style="color: #667eea;">â±ï¸ Ø²Ù…Ø§Ù†</h3>
                    <p style="font-size: 2em; font-weight: 700; color: #764ba2;">~4</p>
                    <p>Ø³Ø§Ø¹Øª Ø¢Ù…ÙˆØ²Ø´</p>
                </div>
            </div>
            
            <div class="key-point box" style="margin-top: 60px; text-align: center;">
                <h2 style="color: #667eea; border: none;">
                    <span class="emoji">ğŸš€</span> Ø­Ø§Ù„Ø§ Ù†ÙˆØ¨Øª Ø´Ù…Ø§Ø³Øª!
                </h2>
                <p style="font-size: 1.5em; line-height: 2.2; margin-top: 30px;">
                    Ø¨Ø§ Ø¯Ø§Ù†Ø´ÛŒ Ú©Ù‡ Ú©Ø³Ø¨ Ú©Ø±Ø¯ÛŒØ¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯:
                </p>
                <ul style="list-style: none; font-size: 1.3em; line-height: 2.5;">
                    <li>ğŸ¯ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø³Ø§Ø²ÛŒØ¯</li>
                    <li>ğŸ¤– Ú†Øªâ€ŒØ¨Ø§Øªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø·Ø±Ø§Ø­ÛŒ Ú©Ù†ÛŒØ¯</li>
                    <li>ğŸ“Š Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ØªÙˆØµÛŒÙ‡ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯</li>
                    <li>ğŸ” Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø³Ø§Ø²ÛŒØ¯</li>
                    <li>ğŸ’¡ Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ø®ÙˆØ¯ Ø±Ø§ Ù¾ÛŒØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯</li>
                </ul>
            </div>
            
            <div style="text-align: center; margin-top: 80px; font-size: 1.8em; color: #667eea; font-weight: 700;">
                <p>Ù…ÙˆÙÙ‚ Ùˆ Ù¾ÛŒØ±ÙˆØ² Ø¨Ø§Ø´ÛŒØ¯! ğŸŒŸ</p>
                <p style="font-size: 0.7em; color: #764ba2; margin-top: 20px;">
                    Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ â¤ï¸ Ø¨Ø±Ø§ÛŒ Ø¹Ù„Ø§Ù‚Ù‡â€ŒÙ…Ù†Ø¯Ø§Ù† Ø¨Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
                </p>
                <p style="font-size: 0.5em; color: #999; margin-top: 40px;">
                    Ù†Ø³Ø®Ù‡ 1.0 | Ø¢Ø°Ø± 1403
                </p>
            </div>
        </div>

    </div>

    <!-- Ø¯Ú©Ù…Ù‡ Ø¨Ø±Ú¯Ø´Øª Ø¨Ù‡ Ø¨Ø§Ù„Ø§ -->
    <button id="backToTop" style="
        position: fixed;
        bottom: 30px;
        left: 30px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 50%;
        width: 60px;
        height: 60px;
        font-size: 24px;
        cursor: pointer;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        display: none;
        z-index: 1000;
        transition: all 0.3s ease;
    ">â¬†ï¸</button>

    <!-- Progress Bar -->
    <div style="
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 4px;
        background: rgba(255,255,255,0.3);
        z-index: 9999;
    ">
        <div id="progressFill" style="
            height: 100%;
            width: 0%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            transition: width 0.3s ease;
        "></div>
    </div>

    <!-- Toast Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ù… Ú©Ù¾ÛŒ -->
    <div id="copyToast" style="
        position: fixed;
        top: 20px;
        right: 20px;
        background: #4caf50;
        color: white;
        padding: 15px 30px;
        border-radius: 10px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        display: none;
        z-index: 10000;
        font-weight: 600;
        font-size: 1.1em;
    ">âœ… Ú©Ù¾ÛŒ Ø´Ø¯!</div>

    <script>
        // Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù† Ú©Ø¯
        document.querySelectorAll('.code').forEach(code => {
            code.style.cursor = 'pointer';
            code.title = 'Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯ ØªØ§ Ú©Ù¾ÛŒ Ø´ÙˆØ¯';
            
            code.addEventListener('click', () => {
                const text = code.innerText;
                navigator.clipboard.writeText(text).then(() => {
                    // Ù†Ù…Ø§ÛŒØ´ toast
                    const toast = document.getElementById('copyToast');
                    toast.style.display = 'block';
                    
                    // ØªØºÛŒÛŒØ± Ø±Ù†Ú¯ Ù…ÙˆÙ‚Øª
                    code.style.background = '#2d5016';
                    
                    setTimeout(() => {
                        toast.style.display = 'none';
                        code.style.background = '#1e293b';
                    }, 2000);
                });
            });
        });

        // Ø¯Ú©Ù…Ù‡ Ø¨Ø±Ú¯Ø´Øª Ø¨Ù‡ Ø¨Ø§Ù„Ø§
        const backToTop = document.getElementById('backToTop');
        
        window.addEventListener('scroll', () => {
            if (window.scrollY > 300) {
                backToTop.style.display = 'block';
            } else {
                backToTop.style.display = 'none';
            }
        });

        backToTop.addEventListener('click', () => {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        backToTop.addEventListener('mouseenter', () => {
            backToTop.style.transform = 'scale(1.1)';
        });

        backToTop.addEventListener('mouseleave', () => {
            backToTop.style.transform = 'scale(1)';
        });

        // Progress Bar
        window.addEventListener('scroll', () => {
            const windowHeight = window.innerHeight;
            const documentHeight = document.documentElement.scrollHeight;
            const scrollTop = window.scrollY;
            const progress = (scrollTop / (documentHeight - windowHeight)) * 100;
            document.getElementById('progressFill').style.width = progress + '%';
        });

        // Intersection Observer Ø¨Ø±Ø§ÛŒ Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ø§Ø³Ù„Ø§ÛŒØ¯Ù‡Ø§
        const slides = document.querySelectorAll('.slide');
        
        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '0';
                    entry.target.style.transform = 'translateY(20px)';
                    
                    setTimeout(() => {
                        entry.target.style.transition = 'all 0.6s ease-out';
                        entry.target.style.opacity = '1';
                        entry.target.style.transform = 'translateY(0)';
                    }, 100);
                }
            });
        }, {
            threshold: 0.1
        });

        slides.forEach(slide => {
            observer.observe(slide);
        });

        // Keyboard shortcuts
        document.addEventListener('keydown', (e) => {
            // Ctrl+P: Print
            if (e.ctrlKey && e.key === 'p') {
                e.preventDefault();
                window.print();
            }
        });

        // Ø¢Ù…Ø§Ø±
        console.log('ğŸ“Š Ø¢Ù…ÙˆØ²Ø´ Embeddings');
        console.log(`ğŸ“„ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ù„Ø§ÛŒØ¯Ù‡Ø§: ${slides.length}`);
        console.log(`ğŸ’» ØªØ¹Ø¯Ø§Ø¯ Ú©Ø¯Ù‡Ø§: ${document.querySelectorAll('.code').length}`);
        console.log(`ğŸ“¦ ØªØ¹Ø¯Ø§Ø¯ Box Ù‡Ø§: ${document.querySelectorAll('.box').length}`);
        console.log('âœ… ÙØ§ÛŒÙ„ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª!');
    </script>

    <style media="print">
        body {
            background: white !important;
        }
        
        .slide {
            page-break-after: always;
            box-shadow: none !important;
            margin: 0 !important;
            padding: 40px !important;
        }
        
        .slide-number {
            display: none;
        }
        
        #progressFill, #backToTop, #copyToast {
            display: none !important;
        }
        
        .code {
            page-break-inside: avoid;
        }
        
        .grid, .comparison {
            page-break-inside: avoid;
        }
        
        table {
            page-break-inside: avoid;
        }
    </style>
</body>
</html>
